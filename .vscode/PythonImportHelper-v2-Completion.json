[
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "FileStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "CommonTokenStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "FileStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "CommonTokenStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "FileStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "CommonTokenStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "FileStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "CommonTokenStream",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "PredictionMode",
        "importPath": "antlr4",
        "description": "antlr4",
        "isExtraImport": true,
        "detail": "antlr4",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "sysconfig",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sysconfig",
        "description": "sysconfig",
        "detail": "sysconfig",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "winreg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "winreg",
        "description": "winreg",
        "detail": "winreg",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx",
        "description": "networkx",
        "isExtraImport": true,
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "hierarchy",
        "importPath": "scipy.cluster",
        "description": "scipy.cluster",
        "isExtraImport": true,
        "detail": "scipy.cluster",
        "documentation": {}
    },
    {
        "label": "distance",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "reverse_cuthill_mckee_ordering",
        "importPath": "networkx.utils",
        "description": "networkx.utils",
        "isExtraImport": true,
        "detail": "networkx.utils",
        "documentation": {}
    },
    {
        "label": "networkx.algorithms.bipartite",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx.algorithms.bipartite",
        "description": "networkx.algorithms.bipartite",
        "detail": "networkx.algorithms.bipartite",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx.generators.degree_seq",
        "description": "networkx.generators.degree_seq",
        "isExtraImport": true,
        "detail": "networkx.generators.degree_seq",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx.generators.atlas",
        "description": "networkx.generators.atlas",
        "isExtraImport": true,
        "detail": "networkx.generators.atlas",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx.generators.atlas",
        "description": "networkx.generators.atlas",
        "isExtraImport": true,
        "detail": "networkx.generators.atlas",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "networkx.generators.atlas",
        "description": "networkx.generators.atlas",
        "isExtraImport": true,
        "detail": "networkx.generators.atlas",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pygraphviz",
        "description": "pygraphviz",
        "isExtraImport": true,
        "detail": "pygraphviz",
        "documentation": {}
    },
    {
        "label": "email",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "email",
        "description": "email",
        "detail": "email",
        "documentation": {}
    },
    {
        "label": "getaddresses",
        "importPath": "email.utils",
        "description": "email.utils",
        "isExtraImport": true,
        "detail": "email.utils",
        "documentation": {}
    },
    {
        "label": "parseaddr",
        "importPath": "email.utils",
        "description": "email.utils",
        "isExtraImport": true,
        "detail": "email.utils",
        "documentation": {}
    },
    {
        "label": "getaddresses",
        "importPath": "email.utils",
        "description": "email.utils",
        "isExtraImport": true,
        "detail": "email.utils",
        "documentation": {}
    },
    {
        "label": "parseaddr",
        "importPath": "email.utils",
        "description": "email.utils",
        "isExtraImport": true,
        "detail": "email.utils",
        "documentation": {}
    },
    {
        "label": "mailbox",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mailbox",
        "description": "mailbox",
        "detail": "mailbox",
        "documentation": {}
    },
    {
        "label": "graph_could_be_isomorphic",
        "importPath": "networkx.algorithms.isomorphism.isomorph",
        "description": "networkx.algorithms.isomorphism.isomorph",
        "isExtraImport": true,
        "detail": "networkx.algorithms.isomorphism.isomorph",
        "documentation": {}
    },
    {
        "label": "graph_could_be_isomorphic",
        "importPath": "networkx.algorithms.isomorphism.isomorph",
        "description": "networkx.algorithms.isomorphism.isomorph",
        "isExtraImport": true,
        "detail": "networkx.algorithms.isomorphism.isomorph",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "itemgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "zipfile,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile.",
        "description": "zipfile.",
        "detail": "zipfile.",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "numpy.linalg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.linalg",
        "description": "numpy.linalg",
        "detail": "numpy.linalg",
        "documentation": {}
    },
    {
        "label": "mlab",
        "importPath": "enthought.mayavi",
        "description": "enthought.mayavi",
        "isExtraImport": true,
        "detail": "enthought.mayavi",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Statement",
        "importPath": "models.Statement",
        "description": "models.Statement",
        "isExtraImport": true,
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "Statement",
        "importPath": "models.Statement",
        "description": "models.Statement",
        "isExtraImport": true,
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "Statement",
        "importPath": "models.Statement",
        "description": "models.Statement",
        "isExtraImport": true,
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "Statement",
        "importPath": "models.Statement",
        "description": "models.Statement",
        "isExtraImport": true,
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "Statement",
        "importPath": "models.Statement",
        "description": "models.Statement",
        "isExtraImport": true,
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "Statement",
        "importPath": "models.Statement",
        "description": "models.Statement",
        "isExtraImport": true,
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "StatementType",
        "importPath": "models.StatementType",
        "description": "models.StatementType",
        "isExtraImport": true,
        "detail": "models.StatementType",
        "documentation": {}
    },
    {
        "label": "StatementType",
        "importPath": "models.StatementType",
        "description": "models.StatementType",
        "isExtraImport": true,
        "detail": "models.StatementType",
        "documentation": {}
    },
    {
        "label": "StatementType",
        "importPath": "models.StatementType",
        "description": "models.StatementType",
        "isExtraImport": true,
        "detail": "models.StatementType",
        "documentation": {}
    },
    {
        "label": "StatementType",
        "importPath": "models.StatementType",
        "description": "models.StatementType",
        "isExtraImport": true,
        "detail": "models.StatementType",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Flow",
        "importPath": "models.Flow",
        "description": "models.Flow",
        "isExtraImport": true,
        "detail": "models.Flow",
        "documentation": {}
    },
    {
        "label": "Flow",
        "importPath": "models.Flow",
        "description": "models.Flow",
        "isExtraImport": true,
        "detail": "models.Flow",
        "documentation": {}
    },
    {
        "label": "Flow",
        "importPath": "models.Flow",
        "description": "models.Flow",
        "isExtraImport": true,
        "detail": "models.Flow",
        "documentation": {}
    },
    {
        "label": "Flow",
        "importPath": "models.Flow",
        "description": "models.Flow",
        "isExtraImport": true,
        "detail": "models.Flow",
        "documentation": {}
    },
    {
        "label": "Flow",
        "importPath": "models.Flow",
        "description": "models.Flow",
        "isExtraImport": true,
        "detail": "models.Flow",
        "documentation": {}
    },
    {
        "label": "ConditionClause",
        "importPath": "models.ConditionClause",
        "description": "models.ConditionClause",
        "isExtraImport": true,
        "detail": "models.ConditionClause",
        "documentation": {}
    },
    {
        "label": "ConditionClause",
        "importPath": "models.ConditionClause",
        "description": "models.ConditionClause",
        "isExtraImport": true,
        "detail": "models.ConditionClause",
        "documentation": {}
    },
    {
        "label": "ConditionClause",
        "importPath": "models.ConditionClause",
        "description": "models.ConditionClause",
        "isExtraImport": true,
        "detail": "models.ConditionClause",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "AssignStatement",
        "importPath": "models.AssignStatement",
        "description": "models.AssignStatement",
        "isExtraImport": true,
        "detail": "models.AssignStatement",
        "documentation": {}
    },
    {
        "label": "AssignStatement",
        "importPath": "models.AssignStatement",
        "description": "models.AssignStatement",
        "isExtraImport": true,
        "detail": "models.AssignStatement",
        "documentation": {}
    },
    {
        "label": "AssignStatement",
        "importPath": "models.AssignStatement",
        "description": "models.AssignStatement",
        "isExtraImport": true,
        "detail": "models.AssignStatement",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "importPath": "helpers.ContextInfoHelper",
        "description": "helpers.ContextInfoHelper",
        "isExtraImport": true,
        "detail": "helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "importPath": "helpers.ContextInfoHelper",
        "description": "helpers.ContextInfoHelper",
        "isExtraImport": true,
        "detail": "helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "importPath": "helpers.ContextInfoHelper",
        "description": "helpers.ContextInfoHelper",
        "isExtraImport": true,
        "detail": "helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "importPath": "helpers.ContextInfoHelper",
        "description": "helpers.ContextInfoHelper",
        "isExtraImport": true,
        "detail": "helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "importPath": "helpers.ContextInfoHelper",
        "description": "helpers.ContextInfoHelper",
        "isExtraImport": true,
        "detail": "helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "importPath": "helpers.ContextInfoHelper",
        "description": "helpers.ContextInfoHelper",
        "isExtraImport": true,
        "detail": "helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Parser",
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "CallStatement",
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "isExtraImport": true,
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "CallCicsStatement",
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "isExtraImport": true,
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "CallStatement",
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "isExtraImport": true,
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "CallStatement",
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "isExtraImport": true,
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "CallCicsStatement",
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "isExtraImport": true,
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "ConditionalStatement",
        "importPath": "models.ConditionalStatement",
        "description": "models.ConditionalStatement",
        "isExtraImport": true,
        "detail": "models.ConditionalStatement",
        "documentation": {}
    },
    {
        "label": "ConditionClause",
        "importPath": "models.ConditionalStatement",
        "description": "models.ConditionalStatement",
        "isExtraImport": true,
        "detail": "models.ConditionalStatement",
        "documentation": {}
    },
    {
        "label": "ConditionalStatement",
        "importPath": "models.ConditionalStatement",
        "description": "models.ConditionalStatement",
        "isExtraImport": true,
        "detail": "models.ConditionalStatement",
        "documentation": {}
    },
    {
        "label": "ConditionalStatement",
        "importPath": "models.ConditionalStatement",
        "description": "models.ConditionalStatement",
        "isExtraImport": true,
        "detail": "models.ConditionalStatement",
        "documentation": {}
    },
    {
        "label": "ParseCallStatements",
        "importPath": "parsers.ParseCallStatements",
        "description": "parsers.ParseCallStatements",
        "isExtraImport": true,
        "detail": "parsers.ParseCallStatements",
        "documentation": {}
    },
    {
        "label": "ParseAssignStatements",
        "importPath": "parsers.ParseAssignStatements",
        "description": "parsers.ParseAssignStatements",
        "isExtraImport": true,
        "detail": "parsers.ParseAssignStatements",
        "documentation": {}
    },
    {
        "label": "ParseConditionalStatements",
        "importPath": "parsers.ParseConditionalStatements",
        "description": "parsers.ParseConditionalStatements",
        "isExtraImport": true,
        "detail": "parsers.ParseConditionalStatements",
        "documentation": {}
    },
    {
        "label": "ParseConditionalStatements",
        "importPath": "parsers.ParseConditionalStatements",
        "description": "parsers.ParseConditionalStatements",
        "isExtraImport": true,
        "detail": "parsers.ParseConditionalStatements",
        "documentation": {}
    },
    {
        "label": "ParseIdentificationDivision",
        "importPath": "IdentificationDivision",
        "description": "IdentificationDivision",
        "isExtraImport": true,
        "detail": "IdentificationDivision",
        "documentation": {}
    },
    {
        "label": "ParseIdentificationDivision",
        "importPath": "IdentificationDivision",
        "description": "IdentificationDivision",
        "isExtraImport": true,
        "detail": "IdentificationDivision",
        "documentation": {}
    },
    {
        "label": "CobolVisitor",
        "importPath": "CobolVisitor",
        "description": "CobolVisitor",
        "isExtraImport": true,
        "detail": "CobolVisitor",
        "documentation": {}
    },
    {
        "label": "CobolVisitor",
        "importPath": "CobolVisitor",
        "description": "CobolVisitor",
        "isExtraImport": true,
        "detail": "CobolVisitor",
        "documentation": {}
    },
    {
        "label": "FlowAnalyzer",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "FlowAnalyzer",
        "description": "FlowAnalyzer",
        "detail": "FlowAnalyzer",
        "documentation": {}
    },
    {
        "label": "FlowAnalyzer",
        "importPath": "FlowAnalyzer",
        "description": "FlowAnalyzer",
        "isExtraImport": true,
        "detail": "FlowAnalyzer",
        "documentation": {}
    },
    {
        "label": "FlowAnalyzer",
        "importPath": "FlowAnalyzer",
        "description": "FlowAnalyzer",
        "isExtraImport": true,
        "detail": "FlowAnalyzer",
        "documentation": {}
    },
    {
        "label": "Cobol85Lexer",
        "importPath": "grammars.Cobol85Lexer",
        "description": "grammars.Cobol85Lexer",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Lexer",
        "documentation": {}
    },
    {
        "label": "Cobol85Lexer",
        "importPath": "grammars.Cobol85Lexer",
        "description": "grammars.Cobol85Lexer",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Lexer",
        "documentation": {}
    },
    {
        "label": "Cobol85Lexer",
        "importPath": "grammars.Cobol85Lexer",
        "description": "grammars.Cobol85Lexer",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Lexer",
        "documentation": {}
    },
    {
        "label": "FlowChartGenerator",
        "importPath": "FlowChartGenerator",
        "description": "FlowChartGenerator",
        "isExtraImport": true,
        "detail": "FlowChartGenerator",
        "documentation": {}
    },
    {
        "label": "FlowChartGenerator",
        "importPath": "FlowChartGenerator",
        "description": "FlowChartGenerator",
        "isExtraImport": true,
        "detail": "FlowChartGenerator",
        "documentation": {}
    },
    {
        "label": "ParseProcedureDivision",
        "importPath": "ParseProcedureDivision",
        "description": "ParseProcedureDivision",
        "isExtraImport": true,
        "detail": "ParseProcedureDivision",
        "documentation": {}
    },
    {
        "label": "ParseProcedureDivision",
        "importPath": "ParseProcedureDivision",
        "description": "ParseProcedureDivision",
        "isExtraImport": true,
        "detail": "ParseProcedureDivision",
        "documentation": {}
    },
    {
        "label": "BPMNGenerator",
        "importPath": "GenerateBPMN",
        "description": "GenerateBPMN",
        "isExtraImport": true,
        "detail": "GenerateBPMN",
        "documentation": {}
    },
    {
        "label": "BPMNGenerator",
        "importPath": "GenerateBPMN",
        "description": "GenerateBPMN",
        "isExtraImport": true,
        "detail": "GenerateBPMN",
        "documentation": {}
    },
    {
        "label": "parse_identification_division",
        "importPath": "parsers.IdentificationDivisionParser",
        "description": "parsers.IdentificationDivisionParser",
        "isExtraImport": true,
        "detail": "parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "ParseStatements",
        "importPath": "parsers.ParseStatements",
        "description": "parsers.ParseStatements",
        "isExtraImport": true,
        "detail": "parsers.ParseStatements",
        "documentation": {}
    },
    {
        "label": "ParseStatements",
        "importPath": "parsers.ParseStatements",
        "description": "parsers.ParseStatements",
        "isExtraImport": true,
        "detail": "parsers.ParseStatements",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "isExtraImport": true,
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "get_children",
        "importPath": "helpers.ContextInfo",
        "description": "helpers.ContextInfo",
        "isExtraImport": true,
        "detail": "helpers.ContextInfo",
        "documentation": {}
    },
    {
        "label": "Cobol85Visitor",
        "importPath": "grammars.Cobol85Visitor",
        "description": "grammars.Cobol85Visitor",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Visitor",
        "documentation": {}
    },
    {
        "label": "Cobol85Visitor",
        "importPath": "grammars.Cobol85Visitor",
        "description": "grammars.Cobol85Visitor",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Visitor",
        "documentation": {}
    },
    {
        "label": "Cobol85Visitor",
        "importPath": "grammars.Cobol85Visitor",
        "description": "grammars.Cobol85Visitor",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Visitor",
        "documentation": {}
    },
    {
        "label": "Cobol85Visitor",
        "importPath": "grammars.Cobol85Visitor",
        "description": "grammars.Cobol85Visitor",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Visitor",
        "documentation": {}
    },
    {
        "label": "Cobol85Visitor",
        "importPath": "grammars.Cobol85Visitor",
        "description": "grammars.Cobol85Visitor",
        "isExtraImport": true,
        "detail": "grammars.Cobol85Visitor",
        "documentation": {}
    },
    {
        "label": "BpmnDiagramGraph",
        "importPath": "bpmn_python.bpmn_diagram_rep",
        "description": "bpmn_python.bpmn_diagram_rep",
        "isExtraImport": true,
        "detail": "bpmn_python.bpmn_diagram_rep",
        "documentation": {}
    },
    {
        "label": "process_cobol_file",
        "importPath": "parsers.CobolParser",
        "description": "parsers.CobolParser",
        "isExtraImport": true,
        "detail": "parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "CustomPreprocessorVisitor",
        "importPath": "PreprocessorVisitor",
        "description": "PreprocessorVisitor",
        "isExtraImport": true,
        "detail": "PreprocessorVisitor",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorLexer",
        "importPath": "grammars.Cobol85PreprocessorLexer",
        "description": "grammars.Cobol85PreprocessorLexer",
        "isExtraImport": true,
        "detail": "grammars.Cobol85PreprocessorLexer",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorParser",
        "importPath": "grammars.Cobol85PreprocessorParser",
        "description": "grammars.Cobol85PreprocessorParser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85PreprocessorParser",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorParser",
        "importPath": "grammars.Cobol85PreprocessorParser",
        "description": "grammars.Cobol85PreprocessorParser",
        "isExtraImport": true,
        "detail": "grammars.Cobol85PreprocessorParser",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorVisitor",
        "importPath": "grammars.Cobol85PreprocessorVisitor",
        "description": "grammars.Cobol85PreprocessorVisitor",
        "isExtraImport": true,
        "detail": "grammars.Cobol85PreprocessorVisitor",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "process_cobol_file",
        "importPath": "parse_cobol",
        "description": "parse_cobol",
        "isExtraImport": true,
        "detail": "parse_cobol",
        "documentation": {}
    },
    {
        "label": "CustomErrorListener",
        "importPath": "custom_error_listener",
        "description": "custom_error_listener",
        "isExtraImport": true,
        "detail": "custom_error_listener",
        "documentation": {}
    },
    {
        "label": "parse_identification_division",
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "isExtraImport": true,
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "parse_procedure_division",
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "isExtraImport": true,
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "parse_working_storage",
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "isExtraImport": true,
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "parse_linkage_section",
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "isExtraImport": true,
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "context_info",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "context_info",
        "description": "context_info",
        "detail": "context_info",
        "documentation": {}
    },
    {
        "label": "parse_statements",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "ErrorListener",
        "importPath": "antlr4.error.ErrorListener",
        "description": "antlr4.error.ErrorListener",
        "isExtraImport": true,
        "detail": "antlr4.error.ErrorListener",
        "documentation": {}
    },
    {
        "label": "Cobol85Lexer",
        "kind": 6,
        "importPath": "grammars.Cobol85Lexer",
        "description": "grammars.Cobol85Lexer",
        "peekOfCode": "class Cobol85Lexer(Lexer):\n    atn = ATNDeserializer().deserialize(serializedATN())\n    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]\n    IDENTIFICATIONLINE = 1\n    AUTHORLINE = 2\n    INSTALLATIONLINE = 3\n    DATE_WRITTENLINE = 4\n    DATE_COMPILEDLINE = 5\n    SECURITYLINE = 6\n    REMARKSLINE = 7",
        "detail": "grammars.Cobol85Lexer",
        "documentation": {}
    },
    {
        "label": "serializedATN",
        "kind": 2,
        "importPath": "grammars.Cobol85Lexer",
        "description": "grammars.Cobol85Lexer",
        "peekOfCode": "def serializedATN():\n    return [\n        4,0,580,6089,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,\n        5,2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,\n        2,13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,\n        7,19,2,20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,\n        2,26,7,26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,\n        7,32,2,33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,\n        2,39,7,39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,\n        7,45,2,46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,",
        "detail": "grammars.Cobol85Lexer",
        "documentation": {}
    },
    {
        "label": "Cobol85Parse",
        "kind": 6,
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "peekOfCode": "class Cobol85Parser ( Parser ):\n    grammarFileName = \"Cobol85.g4\"\n    atn = ATNDeserializer().deserialize(serializedATN())\n    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]\n    sharedContextCache = PredictionContextCache()\n    literalNames = [ \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"'MAP'\", \"'MAPSET'\", \"'XCTL'\", \"'FORMATTIME'\", \"'EXEC'\", \n                     \"'CICS'\", \"'END-EXEC'\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", ",
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "serializedATN",
        "kind": 2,
        "importPath": "grammars.Cobol85Parser",
        "description": "grammars.Cobol85Parser",
        "peekOfCode": "def serializedATN():\n    return [\n        4,1,580,6358,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,\n        7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,\n        13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,\n        20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,\n        26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,\n        33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,\n        39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,45,2,\n        46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,52,7,",
        "detail": "grammars.Cobol85Parser",
        "documentation": {}
    },
    {
        "label": "Cobol85Listener",
        "kind": 6,
        "importPath": "grammars.Cobol85Listener",
        "description": "grammars.Cobol85Listener",
        "peekOfCode": "class Cobol85Listener(ParseTreeListener):\n    # Enter a parse tree produced by Cobol85Parser#startRule.\n    def enterStartRule(self, ctx:Cobol85Parser.StartRuleContext):\n        pass\n    # Exit a parse tree produced by Cobol85Parser#startRule.\n    def exitStartRule(self, ctx:Cobol85Parser.StartRuleContext):\n        pass\n    # Enter a parse tree produced by Cobol85Parser#compilationUnit.\n    def enterCompilationUnit(self, ctx:Cobol85Parser.CompilationUnitContext):\n        pass",
        "detail": "grammars.Cobol85Listener",
        "documentation": {}
    },
    {
        "label": "Cobol85Visitor",
        "kind": 6,
        "importPath": "grammars.Cobol85Visitor",
        "description": "grammars.Cobol85Visitor",
        "peekOfCode": "class Cobol85Visitor(ParseTreeVisitor):\n    # Visit a parse tree produced by Cobol85Parser#startRule.\n    def visitStartRule(self, ctx:Cobol85Parser.StartRuleContext):\n        return self.visitChildren(ctx)\n    # Visit a parse tree produced by Cobol85Parser#compilationUnit.\n    def visitCompilationUnit(self, ctx:Cobol85Parser.CompilationUnitContext):\n        return self.visitChildren(ctx)\n    # Visit a parse tree produced by Cobol85Parser#programUnit.\n    def visitProgramUnit(self, ctx:Cobol85Parser.ProgramUnitContext):\n        return self.visitChildren(ctx)",
        "detail": "grammars.Cobol85Visitor",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorLexer",
        "kind": 6,
        "importPath": "grammars.Cobol85PreprocessorLexer",
        "description": "grammars.Cobol85PreprocessorLexer",
        "peekOfCode": "class Cobol85PreprocessorLexer(Lexer):\n    atn = ATNDeserializer().deserialize(serializedATN())\n    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]\n    ADATA = 1\n    ADV = 2\n    ALIAS = 3\n    ANSI = 4\n    ANY = 5\n    APOST = 6\n    AR = 7",
        "detail": "grammars.Cobol85PreprocessorLexer",
        "documentation": {}
    },
    {
        "label": "serializedATN",
        "kind": 2,
        "importPath": "grammars.Cobol85PreprocessorLexer",
        "description": "grammars.Cobol85PreprocessorLexer",
        "peekOfCode": "def serializedATN():\n    return [\n        4,0,292,2516,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,\n        5,2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,\n        2,13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,\n        7,19,2,20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,\n        2,26,7,26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,\n        7,32,2,33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,\n        2,39,7,39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,\n        7,45,2,46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,",
        "detail": "grammars.Cobol85PreprocessorLexer",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorParse",
        "kind": 6,
        "importPath": "grammars.Cobol85PreprocessorParser",
        "description": "grammars.Cobol85PreprocessorParser",
        "peekOfCode": "class Cobol85PreprocessorParser ( Parser ):\n    grammarFileName = \"Cobol85Preprocessor.g4\"\n    atn = ATNDeserializer().deserialize(serializedATN())\n    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]\n    sharedContextCache = PredictionContextCache()\n    literalNames = [ \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \n                     \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", \"<INVALID>\", ",
        "detail": "grammars.Cobol85PreprocessorParser",
        "documentation": {}
    },
    {
        "label": "serializedATN",
        "kind": 2,
        "importPath": "grammars.Cobol85PreprocessorParser",
        "description": "grammars.Cobol85PreprocessorParser",
        "peekOfCode": "def serializedATN():\n    return [\n        4,1,292,678,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,\n        7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,\n        13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,\n        20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,\n        26,2,27,7,27,2,28,7,28,2,29,7,29,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,\n        1,0,1,0,1,0,1,0,5,0,73,8,0,10,0,12,0,76,9,0,1,0,1,0,1,1,1,1,3,1,\n        82,8,1,1,1,1,1,4,1,86,8,1,11,1,12,1,87,1,2,1,2,1,2,1,2,3,2,94,8,\n        2,1,2,5,2,97,8,2,10,2,12,2,100,9,2,1,2,1,2,1,3,1,3,1,3,1,3,1,3,1,",
        "detail": "grammars.Cobol85PreprocessorParser",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorListener",
        "kind": 6,
        "importPath": "grammars.Cobol85PreprocessorListener",
        "description": "grammars.Cobol85PreprocessorListener",
        "peekOfCode": "class Cobol85PreprocessorListener(ParseTreeListener):\n    # Enter a parse tree produced by Cobol85PreprocessorParser#startRule.\n    def enterStartRule(self, ctx:Cobol85PreprocessorParser.StartRuleContext):\n        pass\n    # Exit a parse tree produced by Cobol85PreprocessorParser#startRule.\n    def exitStartRule(self, ctx:Cobol85PreprocessorParser.StartRuleContext):\n        pass\n    # Enter a parse tree produced by Cobol85PreprocessorParser#compilerOptions.\n    def enterCompilerOptions(self, ctx:Cobol85PreprocessorParser.CompilerOptionsContext):\n        pass",
        "detail": "grammars.Cobol85PreprocessorListener",
        "documentation": {}
    },
    {
        "label": "Cobol85PreprocessorVisitor",
        "kind": 6,
        "importPath": "grammars.Cobol85PreprocessorVisitor",
        "description": "grammars.Cobol85PreprocessorVisitor",
        "peekOfCode": "class Cobol85PreprocessorVisitor(ParseTreeVisitor):\n    # Visit a parse tree produced by Cobol85PreprocessorParser#startRule.\n    def visitStartRule(self, ctx:Cobol85PreprocessorParser.StartRuleContext):\n        return self.visitChildren(ctx)\n    # Visit a parse tree produced by Cobol85PreprocessorParser#compilerOptions.\n    def visitCompilerOptions(self, ctx:Cobol85PreprocessorParser.CompilerOptionsContext):\n        return self.visitChildren(ctx)\n    # Visit a parse tree produced by Cobol85PreprocessorParser#compilerXOpts.\n    def visitCompilerXOpts(self, ctx:Cobol85PreprocessorParser.CompilerXOptsContext):\n        return self.visitChildren(ctx)",
        "detail": "grammars.Cobol85PreprocessorVisitor",
        "documentation": {}
    },
    {
        "label": "Tee",
        "kind": 6,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "class Tee:\n    def __init__(self, file):\n        self.f = file\n    def write(self, what):\n        if self.f is not None:\n            try:\n                self.f.write(what.replace(\"\\n\", \"\\r\\n\"))\n            except OSError:\n                pass\n        tee_f.write(what)",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "CopyTo",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def CopyTo(desc, src, dest):\n    import win32api\n    import win32con\n    while 1:\n        try:\n            win32api.CopyFile(src, dest, 0)\n            return\n        except win32api.error as details:\n            if details.winerror == 5:  # access denied - user not admin.\n                raise",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "LoadSystemModule",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def LoadSystemModule(lib_dir, modname):\n    # See if this is a debug build.\n    import importlib.machinery\n    import importlib.util\n    suffix = \"_d\" if \"_d.pyd\" in importlib.machinery.EXTENSION_SUFFIXES else \"\"\n    filename = \"%s%d%d%s.dll\" % (\n        modname,\n        sys.version_info.major,\n        sys.version_info.minor,\n        suffix,",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "SetPyKeyVal",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def SetPyKeyVal(key_name, value_name, value):\n    root_hkey = get_root_hkey()\n    root_key = winreg.OpenKey(root_hkey, root_key_name)\n    try:\n        my_key = winreg.CreateKey(root_key, key_name)\n        try:\n            winreg.SetValueEx(my_key, value_name, 0, winreg.REG_SZ, value)\n            if verbose:\n                print(f\"-> {root_key_name}\\\\{key_name}[{value_name}]={value!r}\")\n        finally:",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "UnsetPyKeyVal",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def UnsetPyKeyVal(key_name, value_name, delete_key=False):\n    root_hkey = get_root_hkey()\n    root_key = winreg.OpenKey(root_hkey, root_key_name)\n    try:\n        my_key = winreg.OpenKey(root_key, key_name, 0, winreg.KEY_SET_VALUE)\n        try:\n            winreg.DeleteValue(my_key, value_name)\n            if verbose:\n                print(f\"-> DELETE {root_key_name}\\\\{key_name}[{value_name}]\")\n        finally:",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "RegisterCOMObjects",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def RegisterCOMObjects(register=True):\n    import win32com.server.register\n    if register:\n        func = win32com.server.register.RegisterClasses\n    else:\n        func = win32com.server.register.UnregisterClasses\n    flags = {}\n    if not verbose:\n        flags[\"quiet\"] = 1\n    for module, klass_name in com_modules:",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "RegisterHelpFile",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def RegisterHelpFile(register=True, lib_dir=None):\n    if lib_dir is None:\n        lib_dir = sysconfig.get_paths()[\"platlib\"]\n    if register:\n        # Register the .chm help file.\n        chm_file = os.path.join(lib_dir, \"PyWin32.chm\")\n        if os.path.isfile(chm_file):\n            # This isn't recursive, so if 'Help' doesn't exist, we croak\n            SetPyKeyVal(\"Help\", None, None)\n            SetPyKeyVal(\"Help\\\\Pythonwin Reference\", None, chm_file)",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "RegisterPythonwin",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def RegisterPythonwin(register=True, lib_dir=None):\n    \"\"\"Add (or remove) Pythonwin to context menu for python scripts.\n    ??? Should probably also add Edit command for pys files also.\n    Also need to remove these keys on uninstall, but there's no function\n        like file_created to add registry entries to uninstall log ???\n    \"\"\"\n    import os\n    if lib_dir is None:\n        lib_dir = sysconfig.get_paths()[\"platlib\"]\n    classes_root = get_root_hkey()",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "get_shortcuts_folder",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def get_shortcuts_folder():\n    if get_root_hkey() == winreg.HKEY_LOCAL_MACHINE:\n        try:\n            fldr = get_special_folder_path(\"CSIDL_COMMON_PROGRAMS\")\n        except OSError:\n            # No CSIDL_COMMON_PROGRAMS on this platform\n            fldr = get_special_folder_path(\"CSIDL_PROGRAMS\")\n    else:\n        # non-admin install - always goes in this user's start menu.\n        fldr = get_special_folder_path(\"CSIDL_PROGRAMS\")",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "get_system_dir",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def get_system_dir():\n    import win32api  # we assume this exists.\n    try:\n        import pythoncom\n        import win32process\n        from win32com.shell import shell, shellcon\n        try:\n            if win32process.IsWow64Process():\n                return shell.SHGetSpecialFolderPath(0, shellcon.CSIDL_SYSTEMX86)\n            return shell.SHGetSpecialFolderPath(0, shellcon.CSIDL_SYSTEM)",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "fixup_dbi",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def fixup_dbi():\n    # We used to have a dbi.pyd with our .pyd files, but now have a .py file.\n    # If the user didn't uninstall, they will find the .pyd which will cause\n    # problems - so handle that.\n    import win32api\n    import win32con\n    pyd_name = os.path.join(os.path.dirname(win32api.__file__), \"dbi.pyd\")\n    pyd_d_name = os.path.join(os.path.dirname(win32api.__file__), \"dbi_d.pyd\")\n    py_name = os.path.join(os.path.dirname(win32con.__file__), \"dbi.py\")\n    for this_pyd in (pyd_name, pyd_d_name):",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "install",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def install(lib_dir):\n    import traceback\n    # The .pth file is now installed as a regular file.\n    # Create the .pth file in the site-packages dir, and use only relative paths\n    # We used to write a .pth directly to sys.prefix - clobber it.\n    if os.path.isfile(os.path.join(sys.prefix, \"pywin32.pth\")):\n        os.unlink(os.path.join(sys.prefix, \"pywin32.pth\"))\n    # The .pth may be new and therefore not loaded in this session.\n    # Setup the paths just in case.\n    for name in \"win32 win32\\\\lib Pythonwin\".split():",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "uninstall",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def uninstall(lib_dir):\n    # First ensure our system modules are loaded from pywin32_system, so\n    # we can remove the ones we copied...\n    LoadSystemModule(lib_dir, \"pywintypes\")\n    LoadSystemModule(lib_dir, \"pythoncom\")\n    try:\n        RegisterCOMObjects(False)\n    except Exception as why:\n        print(f\"Failed to unregister COM objects: {why}\")\n    try:",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "verify_destination",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def verify_destination(location):\n    if not os.path.isdir(location):\n        raise argparse.ArgumentTypeError(f'Path \"{location}\" does not exist!')\n    return location\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\"\"\"A post-install script for the pywin32 extensions.\n    * Typical usage:\n    > python pywin32_postinstall.py -install",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\"\"\"A post-install script for the pywin32 extensions.\n    * Typical usage:\n    > python pywin32_postinstall.py -install\n    If you installed pywin32 via a .exe installer, this should be run\n    automatically after installation, but if it fails you can run it again.\n    If you installed pywin32 via PIP, you almost certainly need to run this to\n    setup the environment correctly.",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "tee_f",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "tee_f = open(os.path.join(tempfile.gettempdir(), \"pywin32_postinstall.log\"), \"w\")\nclass Tee:\n    def __init__(self, file):\n        self.f = file\n    def write(self, what):\n        if self.f is not None:\n            try:\n                self.f.write(what.replace(\"\\n\", \"\\r\\n\"))\n            except OSError:\n                pass",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "sys.stderr",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "sys.stderr = Tee(sys.stderr)\nsys.stdout = Tee(sys.stdout)\ncom_modules = [\n    # module_name,                      class_names\n    (\"win32com.servers.interp\", \"Interpreter\"),\n    (\"win32com.servers.dictionary\", \"DictionaryPolicy\"),\n    (\"win32com.axscript.client.pyscript\", \"PyScript\"),\n]\n# Is this a 'silent' install - ie, avoid all dialogs.\n# Different than 'verbose'",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "sys.stdout",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "sys.stdout = Tee(sys.stdout)\ncom_modules = [\n    # module_name,                      class_names\n    (\"win32com.servers.interp\", \"Interpreter\"),\n    (\"win32com.servers.dictionary\", \"DictionaryPolicy\"),\n    (\"win32com.axscript.client.pyscript\", \"PyScript\"),\n]\n# Is this a 'silent' install - ie, avoid all dialogs.\n# Different than 'verbose'\nsilent = 0",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "com_modules",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "com_modules = [\n    # module_name,                      class_names\n    (\"win32com.servers.interp\", \"Interpreter\"),\n    (\"win32com.servers.dictionary\", \"DictionaryPolicy\"),\n    (\"win32com.axscript.client.pyscript\", \"PyScript\"),\n]\n# Is this a 'silent' install - ie, avoid all dialogs.\n# Different than 'verbose'\nsilent = 0\n# Verbosity of output messages.",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "silent",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "silent = 0\n# Verbosity of output messages.\nverbose = 1\nroot_key_name = \"Software\\\\Python\\\\PythonCore\\\\\" + sys.winver\ntry:\n    # When this script is run from inside the bdist_wininst installer,\n    # file_created() and directory_created() are additional builtin\n    # functions which write lines to PythonXX\\pywin32-install.log. This is\n    # a list of actions for the uninstaller, the format is inspired by what\n    # the Wise installer also creates.",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "verbose",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "verbose = 1\nroot_key_name = \"Software\\\\Python\\\\PythonCore\\\\\" + sys.winver\ntry:\n    # When this script is run from inside the bdist_wininst installer,\n    # file_created() and directory_created() are additional builtin\n    # functions which write lines to PythonXX\\pywin32-install.log. This is\n    # a list of actions for the uninstaller, the format is inspired by what\n    # the Wise installer also creates.\n    file_created  # type: ignore[used-before-def]\n    # 3.10 stopped supporting bdist_wininst, but we can still build them with 3.9.",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "root_key_name",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_postinstall",
        "description": "dev.Scripts.pywin32_postinstall",
        "peekOfCode": "root_key_name = \"Software\\\\Python\\\\PythonCore\\\\\" + sys.winver\ntry:\n    # When this script is run from inside the bdist_wininst installer,\n    # file_created() and directory_created() are additional builtin\n    # functions which write lines to PythonXX\\pywin32-install.log. This is\n    # a list of actions for the uninstaller, the format is inspired by what\n    # the Wise installer also creates.\n    file_created  # type: ignore[used-before-def]\n    # 3.10 stopped supporting bdist_wininst, but we can still build them with 3.9.\n    # This can be kept until Python 3.9 or exe installers support is dropped.",
        "detail": "dev.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "run_test",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_testall",
        "description": "dev.Scripts.pywin32_testall",
        "peekOfCode": "def run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)\n    # some tests prefer to be run from their directory.\n    cmd = [sys.executable, \"-u\", scriptname] + cmdline_extras\n    print(\"--- Running '%s' ---\" % script)\n    sys.stdout.flush()\n    result = subprocess.run(cmd, check=False, cwd=dirname)\n    print(f\"*** Test script '{script}' exited with {result.returncode}\")\n    sys.stdout.flush()\n    if result.returncode:",
        "detail": "dev.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "find_and_run",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_testall",
        "description": "dev.Scripts.pywin32_testall",
        "peekOfCode": "def find_and_run(possible_locations, extras):\n    for maybe in possible_locations:\n        if os.path.isfile(maybe):\n            run_test(maybe, extras)\n            break\n    else:\n        raise RuntimeError(\n            \"Failed to locate a test script in one of %s\" % possible_locations\n        )\ndef main():",
        "detail": "dev.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "dev.Scripts.pywin32_testall",
        "description": "dev.Scripts.pywin32_testall",
        "peekOfCode": "def main():\n    import argparse\n    code_directories = [this_dir] + site_packages\n    parser = argparse.ArgumentParser(\n        description=\"A script to trigger tests in all subprojects of PyWin32.\"\n    )\n    parser.add_argument(\n        \"-no-user-interaction\",\n        default=False,\n        action=\"store_true\",",
        "detail": "dev.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "this_dir",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_testall",
        "description": "dev.Scripts.pywin32_testall",
        "peekOfCode": "this_dir = os.path.dirname(__file__)\nsite_packages = [\n    site.getusersitepackages(),\n] + site.getsitepackages()\nfailures = []\n# Run a test using subprocess and wait for the result.\n# If we get an returncode != 0, we know that there was an error, but we don't\n# abort immediately - we run as many tests as we can.\ndef run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)",
        "detail": "dev.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "site_packages",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_testall",
        "description": "dev.Scripts.pywin32_testall",
        "peekOfCode": "site_packages = [\n    site.getusersitepackages(),\n] + site.getsitepackages()\nfailures = []\n# Run a test using subprocess and wait for the result.\n# If we get an returncode != 0, we know that there was an error, but we don't\n# abort immediately - we run as many tests as we can.\ndef run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)\n    # some tests prefer to be run from their directory.",
        "detail": "dev.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "failures",
        "kind": 5,
        "importPath": "dev.Scripts.pywin32_testall",
        "description": "dev.Scripts.pywin32_testall",
        "peekOfCode": "failures = []\n# Run a test using subprocess and wait for the result.\n# If we get an returncode != 0, we know that there was an error, but we don't\n# abort immediately - we run as many tests as we can.\ndef run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)\n    # some tests prefer to be run from their directory.\n    cmd = [sys.executable, \"-u\", scriptname] + cmdline_extras\n    print(\"--- Running '%s' ---\" % script)\n    sys.stdout.flush()",
        "detail": "dev.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "create_hc",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "def create_hc(G):\n    \"\"\"Creates hierarchical cluster of graph G from distance matrix\"\"\"\n    path_length=nx.all_pairs_shortest_path_length(G)\n    distances=numpy.zeros((len(G),len(G)))\n    for u,p in path_length.items():\n        for v,d in p.items():\n            distances[u][v]=d\n    # Create hierarchical cluster\n    Y=distance.squareform(distances)\n    Z=hierarchy.complete(Y)  # Creates HC using farthest point linkage",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\ttitle",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\ttitle = {Social Networks of Drug Users in {High-Risk} Sites: Finding the Connections},\n\tvolume = {6},\n\tshorttitle = {Social Networks of Drug Users in {High-Risk} Sites},\n\turl = {http://dx.doi.org/10.1023/A:1015457400897},\n\tdoi = {10.1023/A:1015457400897},\n\tnumber = {2},\n\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tvolume",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tvolume = {6},\n\tshorttitle = {Social Networks of Drug Users in {High-Risk} Sites},\n\turl = {http://dx.doi.org/10.1023/A:1015457400897},\n\tdoi = {10.1023/A:1015457400897},\n\tnumber = {2},\n\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tshorttitle",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tshorttitle = {Social Networks of Drug Users in {High-Risk} Sites},\n\turl = {http://dx.doi.org/10.1023/A:1015457400897},\n\tdoi = {10.1023/A:1015457400897},\n\tnumber = {2},\n\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\turl",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\turl = {http://dx.doi.org/10.1023/A:1015457400897},\n\tdoi = {10.1023/A:1015457400897},\n\tnumber = {2},\n\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tdoi",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tdoi = {10.1023/A:1015457400897},\n\tnumber = {2},\n\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tnumber",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tnumber = {2},\n\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>\nfrom collections import defaultdict",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tjournal",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tjournal = {{AIDS} and Behavior},\n\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>\nfrom collections import defaultdict\nimport networkx as nx",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tauthor",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tauthor = {Margaret R. Weeks and Scott Clair and Stephen P. Borgatti and Kim Radda and Jean J. Schensul},\n\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>\nfrom collections import defaultdict\nimport networkx as nx\nimport numpy",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tmonth",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tmonth = jun,\n\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>\nfrom collections import defaultdict\nimport networkx as nx\nimport numpy\nfrom scipy.cluster import hierarchy",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tyear",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tyear = {2002},\n\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>\nfrom collections import defaultdict\nimport networkx as nx\nimport numpy\nfrom scipy.cluster import hierarchy\nfrom scipy.spatial import distance",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "\tpages",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "peekOfCode": "\tpages = {193--206}\n}\n\"\"\"\n# Authors:  Drew Conway <drew.conway@nyu.edu>, Aric Hagberg <hagberg@lanl.gov>\nfrom collections import defaultdict\nimport networkx as nx\nimport numpy\nfrom scipy.cluster import hierarchy\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.blockmodel",
        "documentation": {}
    },
    {
        "label": "rcm",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "peekOfCode": "rcm = list(reverse_cuthill_mckee_ordering(G))\nprint(\"ordering\",rcm)\nprint(\"unordered Laplacian matrix\")\nA = nx.laplacian_matrix(G)\nx,y = np.nonzero(A)\n#print(\"lower bandwidth:\",(y-x).max())\n#print(\"upper bandwidth:\",(x-y).max())\nprint(\"bandwidth: %d\"%((y-x).max()+(x-y).max()+1))\nprint(A)\nB = nx.laplacian_matrix(G,nodelist=rcm)",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "peekOfCode": "A = nx.laplacian_matrix(G)\nx,y = np.nonzero(A)\n#print(\"lower bandwidth:\",(y-x).max())\n#print(\"upper bandwidth:\",(x-y).max())\nprint(\"bandwidth: %d\"%((y-x).max()+(x-y).max()+1))\nprint(A)\nB = nx.laplacian_matrix(G,nodelist=rcm)\nprint(\"low-bandwidth Laplacian matrix\")\nx,y = np.nonzero(B)\n#print(\"lower bandwidth:\",(y-x).max())",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "documentation": {}
    },
    {
        "label": "x,y",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "peekOfCode": "x,y = np.nonzero(A)\n#print(\"lower bandwidth:\",(y-x).max())\n#print(\"upper bandwidth:\",(x-y).max())\nprint(\"bandwidth: %d\"%((y-x).max()+(x-y).max()+1))\nprint(A)\nB = nx.laplacian_matrix(G,nodelist=rcm)\nprint(\"low-bandwidth Laplacian matrix\")\nx,y = np.nonzero(B)\n#print(\"lower bandwidth:\",(y-x).max())\n#print(\"upper bandwidth:\",(x-y).max())",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "documentation": {}
    },
    {
        "label": "B",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "peekOfCode": "B = nx.laplacian_matrix(G,nodelist=rcm)\nprint(\"low-bandwidth Laplacian matrix\")\nx,y = np.nonzero(B)\n#print(\"lower bandwidth:\",(y-x).max())\n#print(\"upper bandwidth:\",(x-y).max())\nprint(\"bandwidth: %d\"%((y-x).max()+(x-y).max()+1))\nprint(B)",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "documentation": {}
    },
    {
        "label": "x,y",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "peekOfCode": "x,y = np.nonzero(B)\n#print(\"lower bandwidth:\",(y-x).max())\n#print(\"upper bandwidth:\",(x-y).max())\nprint(\"bandwidth: %d\"%((y-x).max()+(x-y).max()+1))\nprint(B)",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.rcm",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "peekOfCode": "G = nx.davis_southern_women_graph()\nwomen = G.graph['top']\nclubs = G.graph['bottom']\nprint(\"Biadjacency matrix\")\nprint(bipartite.biadjacency_matrix(G,women,clubs))\n# project bipartite graph onto women nodes\nW = bipartite.projected_graph(G, women)\nprint('') \nprint(\"#Friends, Member\")\nfor w in women:",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "documentation": {}
    },
    {
        "label": "women",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "peekOfCode": "women = G.graph['top']\nclubs = G.graph['bottom']\nprint(\"Biadjacency matrix\")\nprint(bipartite.biadjacency_matrix(G,women,clubs))\n# project bipartite graph onto women nodes\nW = bipartite.projected_graph(G, women)\nprint('') \nprint(\"#Friends, Member\")\nfor w in women:\n    print('%d %s' % (W.degree(w),w))",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "documentation": {}
    },
    {
        "label": "clubs",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "peekOfCode": "clubs = G.graph['bottom']\nprint(\"Biadjacency matrix\")\nprint(bipartite.biadjacency_matrix(G,women,clubs))\n# project bipartite graph onto women nodes\nW = bipartite.projected_graph(G, women)\nprint('') \nprint(\"#Friends, Member\")\nfor w in women:\n    print('%d %s' % (W.degree(w),w))\n# project bipartite graph onto women nodes keeping number of co-occurence",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "documentation": {}
    },
    {
        "label": "W",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "peekOfCode": "W = bipartite.projected_graph(G, women)\nprint('') \nprint(\"#Friends, Member\")\nfor w in women:\n    print('%d %s' % (W.degree(w),w))\n# project bipartite graph onto women nodes keeping number of co-occurence\n# the degree computed is weighted and counts the total number of shared contacts\nW = bipartite.weighted_projected_graph(G, women)\nprint('') \nprint(\"#Friend meetings, Member\")",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "documentation": {}
    },
    {
        "label": "W",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "description": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "peekOfCode": "W = bipartite.weighted_projected_graph(G, women)\nprint('') \nprint(\"#Friend meetings, Member\")\nfor w in women:\n    print('%d %s' % (W.degree(w,weight='weight'),w))",
        "detail": "dev.share.doc.networkx-1.11.examples.algorithms.davis_club",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.basic.properties",
        "description": "dev.share.doc.networkx-1.11.examples.basic.properties",
        "peekOfCode": "G = lollipop_graph(4,6)\npathlengths=[]\nprint(\"source vertex {target:length, }\")\nfor v in G.nodes():\n    spl=single_source_shortest_path_length(G,v)\n    print('%s %s' % (v,spl))\n    for p in spl.values():\n        pathlengths.append(p)\nprint('')\nprint(\"average shortest path length %s\" % (sum(pathlengths)/len(pathlengths)))",
        "detail": "dev.share.doc.networkx-1.11.examples.basic.properties",
        "documentation": {}
    },
    {
        "label": "chess_pgn_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.multigraph.chess_masters",
        "description": "dev.share.doc.networkx-1.11.examples.multigraph.chess_masters",
        "peekOfCode": "def chess_pgn_graph(pgn_file=\"chess_masters_WCC.pgn.bz2\"):\n    \"\"\"Read chess games in pgn format in pgn_file.\n    Filenames ending in .gz or .bz2 will be uncompressed.\n    Return the MultiDiGraph of players connected by a chess game.\n    Edges contain game data in a dict.\n    \"\"\"\n    import bz2\n    G=nx.MultiDiGraph()\n    game={}\n    datafile = bz2.BZ2File(pgn_file)",
        "detail": "dev.share.doc.networkx-1.11.examples.multigraph.chess_masters",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "peekOfCode": "G = nx.complete_graph(5)   # start with K5 in networkx\nA = nx.nx_agraph.to_agraph(G)        # convert to a graphviz graph\nX1 = nx.nx_agraph.from_agraph(A)     # convert back to networkx (but as Graph)\nX2 = nx.Graph(A)          # fancy way to do conversion\nG1 = nx.Graph(X1)          # now make it a Graph\nA.write('k5.dot')     # write to dot file\nX3 = nx.nx_agraph.read_dot('k5.dot') # read from dotfile",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "peekOfCode": "A = nx.nx_agraph.to_agraph(G)        # convert to a graphviz graph\nX1 = nx.nx_agraph.from_agraph(A)     # convert back to networkx (but as Graph)\nX2 = nx.Graph(A)          # fancy way to do conversion\nG1 = nx.Graph(X1)          # now make it a Graph\nA.write('k5.dot')     # write to dot file\nX3 = nx.nx_agraph.read_dot('k5.dot') # read from dotfile",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "documentation": {}
    },
    {
        "label": "X1",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "peekOfCode": "X1 = nx.nx_agraph.from_agraph(A)     # convert back to networkx (but as Graph)\nX2 = nx.Graph(A)          # fancy way to do conversion\nG1 = nx.Graph(X1)          # now make it a Graph\nA.write('k5.dot')     # write to dot file\nX3 = nx.nx_agraph.read_dot('k5.dot') # read from dotfile",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "documentation": {}
    },
    {
        "label": "X2",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "peekOfCode": "X2 = nx.Graph(A)          # fancy way to do conversion\nG1 = nx.Graph(X1)          # now make it a Graph\nA.write('k5.dot')     # write to dot file\nX3 = nx.nx_agraph.read_dot('k5.dot') # read from dotfile",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "documentation": {}
    },
    {
        "label": "G1",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "peekOfCode": "G1 = nx.Graph(X1)          # now make it a Graph\nA.write('k5.dot')     # write to dot file\nX3 = nx.nx_agraph.read_dot('k5.dot') # read from dotfile",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "documentation": {}
    },
    {
        "label": "X3",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "peekOfCode": "X3 = nx.nx_agraph.read_dot('k5.dot') # read from dotfile",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_simple",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "peekOfCode": "G = nx.Graph()\n# ad edges with red color\nG.add_edge(1, 2, color='red')\nG.add_edge(2, 3, color='red')\n# add nodes 3 and 4\nG.add_node(3)\nG.add_node(4)\n# convert to a graphviz agraph\nA = nx.nx_agraph.to_agraph(G)\n# write to dot file",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "peekOfCode": "A = nx.nx_agraph.to_agraph(G)\n# write to dot file\nA.write('k5_attributes.dot')\n# convert back to networkx Graph with attributes on edges and\n# default attributes as dictionary data\nX = nx.nx_agraph.from_agraph(A)\nprint(\"edges\")\nprint(X.edges(data=True))\nprint(\"default graph attributes\")\nprint(X.graph)",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "peekOfCode": "X = nx.nx_agraph.from_agraph(A)\nprint(\"edges\")\nprint(X.edges(data=True))\nprint(\"default graph attributes\")\nprint(X.graph)\nprint(\"node node attributes\")\nprint(X.node)",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_attributes",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_draw",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_draw",
        "peekOfCode": "G = nx.complete_graph(5)   # start with K5 in networkx\nA = nx.nx_agraph.to_agraph(G)        # convert to a graphviz graph\nA.layout()            # neato layout\nA.draw(\"k5.ps\")       # write postscript in k5.ps with neato layout",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_draw",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_draw",
        "description": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_draw",
        "peekOfCode": "A = nx.nx_agraph.to_agraph(G)        # convert to a graphviz graph\nA.layout()            # neato layout\nA.draw(\"k5.ps\")       # write postscript in k5.ps with neato layout",
        "detail": "dev.share.doc.networkx-1.11.examples.pygraphviz.pygraphviz_draw",
        "documentation": {}
    },
    {
        "label": "atlas",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.atlas2",
        "description": "dev.share.doc.networkx-1.11.examples.graph.atlas2",
        "peekOfCode": "atlas = graph_atlas_g()[0:20]\nfor G in atlas:\n    print(\"graph %s has %d nodes with %d edges\"\n          %(G.name,NX.number_of_nodes(G),NX.number_of_edges(G)))\n    A = nx.nx_agraph.to_agraph(G)\n    A.graph_attr['label'] = G.name\n    # set default node attributes\n    A.node_attr['color'] = 'red'\n    A.node_attr['style'] = 'filled'\n    A.node_attr['shape'] = 'circle'",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.atlas2",
        "documentation": {}
    },
    {
        "label": "msgfactory",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.unix_email",
        "description": "dev.share.doc.networkx-1.11.examples.graph.unix_email",
        "peekOfCode": "def msgfactory(fp):\n    try:\n        return email.message_from_file(fp)\n    except email.Errors.MessageParseError:\n        # Don't return None since that will stop the mailbox iterator\n        return ''\nif __name__ == '__main__':\n    import networkx as nx\n    try:\n        import matplotlib.pyplot as plt",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.unix_email",
        "documentation": {}
    },
    {
        "label": "atlas6",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.atlas",
        "description": "dev.share.doc.networkx-1.11.examples.graph.atlas",
        "peekOfCode": "def atlas6():\n    \"\"\" Return the atlas of all connected graphs of 6 nodes or less.\n        Attempt to check for isomorphisms and remove.\n    \"\"\"\n    Atlas = graph_atlas_g()[0:208] # 208\n    # remove isolated nodes, only connected graphs are left\n    U = nx.Graph() # graph for union of all graphs in atlas\n    for G in Atlas:\n        zerodegree = [n for n in G if G.degree(n)==0]\n        for n in zerodegree:",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.atlas",
        "documentation": {}
    },
    {
        "label": "iso",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.atlas",
        "description": "dev.share.doc.networkx-1.11.examples.graph.atlas",
        "peekOfCode": "def iso(G1, glist):\n    \"\"\"Quick and dirty nonisomorphism checker used to check isomorphisms.\"\"\"\n    for G2 in glist:\n        if isomorphic(G1, G2):\n            return True\n    return False\nif __name__ == '__main__':\n    G=atlas6()\n    print(\"graph has %d nodes with %d edges\"\\\n          %(nx.number_of_nodes(G), nx.number_of_edges(G)))",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.atlas",
        "documentation": {}
    },
    {
        "label": "roget_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.roget",
        "description": "dev.share.doc.networkx-1.11.examples.graph.roget",
        "peekOfCode": "def roget_graph():\n    \"\"\" Return the thesaurus graph from the roget.dat example in\n    the Stanford Graph Base.\n    \"\"\"\n    # open file roget_dat.txt.gz (or roget_dat.txt)\n    import gzip\n    fh=gzip.open('roget_dat.txt.gz','r')\n    G=DiGraph()\n    for line in fh.readlines():\n        line = line.decode()",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.roget",
        "documentation": {}
    },
    {
        "label": "miles_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.knuth_miles",
        "description": "dev.share.doc.networkx-1.11.examples.graph.knuth_miles",
        "peekOfCode": "def miles_graph():\n    \"\"\" Return the cites example graph in miles_dat.txt\n        from the Stanford GraphBase.\n    \"\"\"\n    # open file miles_dat.txt.gz (or miles_dat.txt)\n    import gzip\n    fh = gzip.open('knuth_miles.txt.gz','r')\n    G=nx.Graph()\n    G.position={}\n    G.population={}",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.knuth_miles",
        "documentation": {}
    },
    {
        "label": "minard_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.napoleon_russian_campaign",
        "description": "dev.share.doc.networkx-1.11.examples.graph.napoleon_russian_campaign",
        "peekOfCode": "def minard_graph():\n    data1=\"\"\"\\\n24.0,54.9,340000,A,1\n24.5,55.0,340000,A,1\n25.5,54.5,340000,A,1\n26.0,54.7,320000,A,1\n27.0,54.8,300000,A,1\n28.0,54.9,280000,A,1\n28.5,55.0,240000,A,1\n29.0,55.1,210000,A,1",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.napoleon_russian_campaign",
        "documentation": {}
    },
    {
        "label": "sock",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.football",
        "description": "dev.share.doc.networkx-1.11.examples.graph.football",
        "peekOfCode": "sock = urllib.urlopen(url)  # open URL\ns=io.BytesIO(sock.read()) # read into BytesIO \"file\"\nsock.close()\nzf = zipfile.ZipFile(s) # zipfile object\ntxt=zf.read('football.txt').decode() # read info file\ngml=zf.read('football.gml').decode() # read gml data\n# throw away bogus first line with # from mejn files\ngml=gml.split('\\n')[1:]\nG=parse_gml(gml) # parse gml data\nprint(txt)",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.football",
        "documentation": {}
    },
    {
        "label": "zf",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.football",
        "description": "dev.share.doc.networkx-1.11.examples.graph.football",
        "peekOfCode": "zf = zipfile.ZipFile(s) # zipfile object\ntxt=zf.read('football.txt').decode() # read info file\ngml=zf.read('football.gml').decode() # read gml data\n# throw away bogus first line with # from mejn files\ngml=gml.split('\\n')[1:]\nG=parse_gml(gml) # parse gml data\nprint(txt)\n# print degree for each team - number of games\nfor n,d in G.degree_iter():\n    print('%s %d' % (n, d))",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.football",
        "documentation": {}
    },
    {
        "label": "generate_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.words",
        "description": "dev.share.doc.networkx-1.11.examples.graph.words",
        "peekOfCode": "def generate_graph(words):\n    from string import ascii_lowercase as lowercase\n    G = nx.Graph(name=\"words\")\n    lookup = dict((c,lowercase.index(c)) for c in lowercase)\n    def edit_distance_one(word):\n        for i in range(len(word)):\n            left, c, right = word[0:i], word[i], word[i+1:]\n            j = lookup[c] # lowercase.index(c)\n            for cc in lowercase[j+1:]:\n                yield left + cc + right",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.words",
        "documentation": {}
    },
    {
        "label": "words_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.graph.words",
        "description": "dev.share.doc.networkx-1.11.examples.graph.words",
        "peekOfCode": "def words_graph():\n    \"\"\"Return the words example graph from the Stanford GraphBase\"\"\"\n    import gzip\n    fh=gzip.open('words_dat.txt.gz','r')\n    words=set()\n    for line in fh.readlines():\n        line = line.decode()\n        if line.startswith('*'):\n            continue\n        w=str(line[0:5])",
        "detail": "dev.share.doc.networkx-1.11.examples.graph.words",
        "documentation": {}
    },
    {
        "label": "lanl_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.lanl_routes",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.lanl_routes",
        "peekOfCode": "def lanl_graph():\n    \"\"\" Return the lanl internet view graph from lanl.edges\n    \"\"\"\n    import networkx as nx\n    try:\n        fh = open('lanl_routes.edgelist' , 'r')\n    except IOError:\n        print(\"lanl.edges not found\")\n        raise\n    G = nx.Graph()",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.lanl_routes",
        "documentation": {}
    },
    {
        "label": "msgfactory",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.unix_email",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.unix_email",
        "peekOfCode": "def msgfactory(fp):\n    try:\n        return email.message_from_file(fp)\n    except email.Errors.MessageParseError:\n        # Don't return None since that will stop the mailbox iterator\n        return ''\nif __name__ == '__main__':\n    import networkx as nx\n    try:\n        import matplotlib.pyplot as plt",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.unix_email",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.circular_tree",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.circular_tree",
        "peekOfCode": "G = nx.balanced_tree(3, 5)\npos = graphviz_layout(G, prog='twopi', args='')\nplt.figure(figsize=(8, 8))\nnx.draw(G, pos, node_size=20, alpha=0.5, node_color=\"blue\", with_labels=False)\nplt.axis('equal')\nplt.savefig('circular_tree.png')\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.circular_tree",
        "documentation": {}
    },
    {
        "label": "pos",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.circular_tree",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.circular_tree",
        "peekOfCode": "pos = graphviz_layout(G, prog='twopi', args='')\nplt.figure(figsize=(8, 8))\nnx.draw(G, pos, node_size=20, alpha=0.5, node_color=\"blue\", with_labels=False)\nplt.axis('equal')\nplt.savefig('circular_tree.png')\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.circular_tree",
        "documentation": {}
    },
    {
        "label": "atlas6",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.atlas",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.atlas",
        "peekOfCode": "def atlas6():\n    \"\"\" Return the atlas of all connected graphs of 6 nodes or less.\n        Attempt to check for isomorphisms and remove.\n    \"\"\"\n    Atlas = graph_atlas_g()[0:208] # 208\n    # remove isolated nodes, only connected graphs are left\n    U = nx.Graph() # graph for union of all graphs in atlas\n    for G in Atlas:\n        zerodegree = [n for n in G if G.degree(n)==0]\n        for n in zerodegree:",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.atlas",
        "documentation": {}
    },
    {
        "label": "iso",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.atlas",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.atlas",
        "peekOfCode": "def iso(G1, glist):\n    \"\"\"Quick and dirty nonisomorphism checker used to check isomorphisms.\"\"\"\n    for G2 in glist:\n        if isomorphic(G1, G2):\n            return True\n    return False\nif __name__ == '__main__':\n    G=atlas6()\n    print(\"graph has %d nodes with %d edges\"\\\n          %(nx.number_of_nodes(G), nx.number_of_edges(G)))",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.atlas",
        "documentation": {}
    },
    {
        "label": "miles_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.knuth_miles",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.knuth_miles",
        "peekOfCode": "def miles_graph():\n    \"\"\" Return the cites example graph in miles_dat.txt\n        from the Stanford GraphBase.\n    \"\"\"\n    # open file miles_dat.txt.gz (or miles_dat.txt)\n    import gzip\n    fh = gzip.open('knuth_miles.txt.gz','r')\n    G=nx.Graph()\n    G.position={}\n    G.population={}",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.knuth_miles",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.degree_histogram",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.degree_histogram",
        "peekOfCode": "G = nx.gnp_random_graph(100,0.02)\ndegree_sequence=sorted(nx.degree(G).values(),reverse=True) # degree sequence\n#print \"Degree sequence\", degree_sequence\ndmax=max(degree_sequence)\nplt.loglog(degree_sequence,'b-',marker='o')\nplt.title(\"Degree rank plot\")\nplt.ylabel(\"degree\")\nplt.xlabel(\"rank\")\n# draw graph in inset\nplt.axes([0.45,0.45,0.45,0.45])",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.degree_histogram",
        "documentation": {}
    },
    {
        "label": "zf",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.sampson",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.sampson",
        "peekOfCode": "zf = zipfile.ZipFile('sampson_data.zip') # zipfile object\ne1=cStringIO.StringIO(zf.read('samplike1.txt')) # read info file\ne2=cStringIO.StringIO(zf.read('samplike2.txt')) # read info file\ne3=cStringIO.StringIO(zf.read('samplike3.txt')) # read info file\nG1=nx.read_edgelist(e1,delimiter='\\t')\nG2=nx.read_edgelist(e2,delimiter='\\t')\nG3=nx.read_edgelist(e3,delimiter='\\t')\npos=nx.spring_layout(G3,iterations=100)\nplt.clf()\nplt.subplot(221)",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.sampson",
        "documentation": {}
    },
    {
        "label": "chess_pgn_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.drawing.chess_masters",
        "description": "dev.share.doc.networkx-1.11.examples.drawing.chess_masters",
        "peekOfCode": "def chess_pgn_graph(pgn_file=\"chess_masters_WCC.pgn.bz2\"):\n    \"\"\"Read chess games in pgn format in pgn_file.\n    Filenames ending in .gz or .bz2 will be uncompressed.\n    Return the MultiDiGraph of players connected by a chess game.\n    Edges contain game data in a dict.\n    \"\"\"\n    import bz2\n    G=nx.MultiDiGraph()\n    game={}\n    datafile = bz2.BZ2File(pgn_file)",
        "detail": "dev.share.doc.networkx-1.11.examples.drawing.chess_masters",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.parallel_betweenness",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.parallel_betweenness",
        "peekOfCode": "def chunks(l, n):\n    \"\"\"Divide a list of nodes `l` in `n` chunks\"\"\"\n    l_c = iter(l)\n    while 1:\n        x = tuple(itertools.islice(l_c, n))\n        if not x:\n            return\n        yield x\ndef _betmap(G_normalized_weight_sources_tuple):\n    \"\"\"Pool for multiprocess only accepts functions with one argument.",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.parallel_betweenness",
        "documentation": {}
    },
    {
        "label": "betweenness_centrality_parallel",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.parallel_betweenness",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.parallel_betweenness",
        "peekOfCode": "def betweenness_centrality_parallel(G, processes=None):\n    \"\"\"Parallel betweenness centrality  function\"\"\"\n    p = Pool(processes=processes)\n    node_divisor = len(p._pool)*4\n    node_chunks = list(chunks(G.nodes(), int(G.order()/node_divisor)))\n    num_chunks = len(node_chunks)\n    bt_sc = p.map(_betmap,\n                  zip([G]*num_chunks,\n                      [True]*num_chunks,\n                      [None]*num_chunks,",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.parallel_betweenness",
        "documentation": {}
    },
    {
        "label": "n",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "peekOfCode": "n = 1000 # 1000 nodes\nm = 5000 # 5000 edges\nG = nx.gnm_random_graph(n,m)\nL = nx.normalized_laplacian_matrix(G)\ne = numpy.linalg.eigvals(L.A)\nprint(\"Largest eigenvalue:\", max(e))\nprint(\"Smallest eigenvalue:\", min(e))\nplt.hist(e,bins=100) # histogram with 100 bins\nplt.xlim(0,2)  # eigenvalues between 0 and 2\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "documentation": {}
    },
    {
        "label": "m",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "peekOfCode": "m = 5000 # 5000 edges\nG = nx.gnm_random_graph(n,m)\nL = nx.normalized_laplacian_matrix(G)\ne = numpy.linalg.eigvals(L.A)\nprint(\"Largest eigenvalue:\", max(e))\nprint(\"Smallest eigenvalue:\", min(e))\nplt.hist(e,bins=100) # histogram with 100 bins\nplt.xlim(0,2)  # eigenvalues between 0 and 2\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "peekOfCode": "G = nx.gnm_random_graph(n,m)\nL = nx.normalized_laplacian_matrix(G)\ne = numpy.linalg.eigvals(L.A)\nprint(\"Largest eigenvalue:\", max(e))\nprint(\"Smallest eigenvalue:\", min(e))\nplt.hist(e,bins=100) # histogram with 100 bins\nplt.xlim(0,2)  # eigenvalues between 0 and 2\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "documentation": {}
    },
    {
        "label": "L",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "peekOfCode": "L = nx.normalized_laplacian_matrix(G)\ne = numpy.linalg.eigvals(L.A)\nprint(\"Largest eigenvalue:\", max(e))\nprint(\"Smallest eigenvalue:\", min(e))\nplt.hist(e,bins=100) # histogram with 100 bins\nplt.xlim(0,2)  # eigenvalues between 0 and 2\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "documentation": {}
    },
    {
        "label": "e",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "peekOfCode": "e = numpy.linalg.eigvals(L.A)\nprint(\"Largest eigenvalue:\", max(e))\nprint(\"Smallest eigenvalue:\", min(e))\nplt.hist(e,bins=100) # histogram with 100 bins\nplt.xlim(0,2)  # eigenvalues between 0 and 2\nplt.show()",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.eigenvalues",
        "documentation": {}
    },
    {
        "label": "digitsrep",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def digitsrep(n,b=10):\n    \"\"\"Return list of digits comprising n represented in base b.\n    n must be a nonnegative integer\"\"\"\n    # very inefficient if you only work with base 10\n    dlist=[]\n    if n<=0:\n        return [0]\n    maxpow=int(floor( log(n)/log(b) + mach_eps ))\n    pow=maxpow\n    while pow>=0:",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "powersum",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def powersum(n,p,b=10):\n    \"\"\"Return sum of digits of n (in base b) raised to the power p.\"\"\"\n    dlist=digitsrep(n,b)\n    sum=0\n    for k in dlist:\n        sum+=k**p\n    return sum\ndef attractor153_graph(n,p,multiple=3,b=10):\n    \"\"\"Return digraph of iterations of powersum(n,3,10).\"\"\"\n    G=DiGraph()",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "attractor153_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def attractor153_graph(n,p,multiple=3,b=10):\n    \"\"\"Return digraph of iterations of powersum(n,3,10).\"\"\"\n    G=DiGraph()\n    for k in range(1,n+1):\n        if k%multiple==0 and k not in G:\n            k1=k\n            knext=powersum(k1,p,b)\n            while k1!=knext:\n                G.add_edge(k1,knext)\n                k1=knext",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "squaring_cycle_graph_old",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def squaring_cycle_graph_old(n,b=10):\n    \"\"\"Return digraph of iterations of powersum(n,2,10).\"\"\"\n    G=DiGraph()\n    for k in range(1,n+1):\n        k1=k\n        G.add_node(k1) # case k1==knext, at least add node\n        knext=powersum(k1,2,b)\n        G.add_edge(k1,knext)\n        while k1!=knext: # stop if fixed point \n             k1=knext",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "sum_of_digits_graph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def sum_of_digits_graph(nmax,b=10):\n    def f(n): return powersum(n,1,b)\n    return discrete_dynamics_digraph(nmax,f)\ndef squaring_cycle_digraph(nmax,b=10):\n    def f(n): return powersum(n,2,b)\n    return discrete_dynamics_digraph(nmax,f)\ndef cubing_153_digraph(nmax):\n    def f(n): return powersum(n,3,10)\n    return discrete_dynamics_digraph(nmax,f)\ndef discrete_dynamics_digraph(nmax,f,itermax=50000):",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "squaring_cycle_digraph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def squaring_cycle_digraph(nmax,b=10):\n    def f(n): return powersum(n,2,b)\n    return discrete_dynamics_digraph(nmax,f)\ndef cubing_153_digraph(nmax):\n    def f(n): return powersum(n,3,10)\n    return discrete_dynamics_digraph(nmax,f)\ndef discrete_dynamics_digraph(nmax,f,itermax=50000):\n    G=DiGraph()\n    for k in range(1,nmax+1):\n        kold=k",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "cubing_153_digraph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def cubing_153_digraph(nmax):\n    def f(n): return powersum(n,3,10)\n    return discrete_dynamics_digraph(nmax,f)\ndef discrete_dynamics_digraph(nmax,f,itermax=50000):\n    G=DiGraph()\n    for k in range(1,nmax+1):\n        kold=k\n        G.add_node(kold)\n        knew=f(kold)\n        G.add_edge(kold,knew)",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "discrete_dynamics_digraph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def discrete_dynamics_digraph(nmax,f,itermax=50000):\n    G=DiGraph()\n    for k in range(1,nmax+1):\n        kold=k\n        G.add_node(kold)\n        knew=f(kold)\n        G.add_edge(kold,knew)\n        while kold!=knew and kold<<itermax: \n        # iterate until fixed point reached or itermax is exceeded\n            kold=knew",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "collatz_problem_digraph",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def collatz_problem_digraph(nmax):\n    def f(n):\n        if n%2==0:\n            return n // 2\n        else:\n            return 3*n+1\n    return discrete_dynamics_digraph(nmax,f)\ndef fixed_points(G):\n    \"\"\"Return a list of fixed points for the discrete dynamical \n    system represented by the digraph G.",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "fixed_points",
        "kind": 2,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "def fixed_points(G):\n    \"\"\"Return a list of fixed points for the discrete dynamical \n    system represented by the digraph G.\n    \"\"\"\n    return [n for n in G if G.out_degree(n)==0]\nif __name__ == \"__main__\":\n    nmax=10000\n    print(\"Building cubing_153_digraph(%d)\"% nmax)\n    G=cubing_153_digraph(nmax)\n    print(\"Resulting digraph has\", len(G), \"nodes and\",",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "f(108)",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "f(108) = 1**3 + 0**3 + 8**3 = 513\nand\nf(513) = 5**3 + 1**3 + 3**3 = 153\nSo, starting at 108 we reach 153 in two iterations,\nrepresented as:\n108->513->153\nComputing all orbits of 3N up to 10**5 reveals that the attractor\n153 is reached in a maximum of 14 iterations. In this code we\nshow that 13 cycles is the maximum required for all integers (in 3N)\nless than 10,000.",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "f(513)",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "description": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "peekOfCode": "f(513) = 5**3 + 1**3 + 3**3 = 153\nSo, starting at 108 we reach 153 in two iterations,\nrepresented as:\n108->513->153\nComputing all orbits of 3N up to 10**5 reveals that the attractor\n153 is reached in a maximum of 14 iterations. In this code we\nshow that 13 cycles is the maximum required for all integers (in 3N)\nless than 10,000.\nThe smallest number that requires 13 iterations to reach 153, is 177, i.e.,\n177->687->1071->345->216->225->141->66->432->99->1458->702->351->153",
        "detail": "dev.share.doc.networkx-1.11.examples.advanced.iterated_dynamical_systems",
        "documentation": {}
    },
    {
        "label": "pts",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "description": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "peekOfCode": "pts = mlab.points3d(xyz[:,0], xyz[:,1], xyz[:,2], \n                    scalars,\n                    scale_factor=0.1,\n                    scale_mode='none',\n                    colormap='Blues',\n                    resolution=20) \npts.mlab_source.dataset.lines = np.array(G.edges())\ntube = mlab.pipeline.tube(pts, tube_radius=0.01)\nmlab.pipeline.surface(tube, color=(0.8, 0.8, 0.8))\nmlab.savefig('mayavi2_spring.png')",
        "detail": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "documentation": {}
    },
    {
        "label": "pts.mlab_source.dataset.lines",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "description": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "peekOfCode": "pts.mlab_source.dataset.lines = np.array(G.edges())\ntube = mlab.pipeline.tube(pts, tube_radius=0.01)\nmlab.pipeline.surface(tube, color=(0.8, 0.8, 0.8))\nmlab.savefig('mayavi2_spring.png')\n# mlab.show() # interactive window",
        "detail": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "documentation": {}
    },
    {
        "label": "tube",
        "kind": 5,
        "importPath": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "description": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "peekOfCode": "tube = mlab.pipeline.tube(pts, tube_radius=0.01)\nmlab.pipeline.surface(tube, color=(0.8, 0.8, 0.8))\nmlab.savefig('mayavi2_spring.png')\n# mlab.show() # interactive window",
        "detail": "dev.share.doc.networkx-1.11.examples.3d_drawing.mayavi2_spring",
        "documentation": {}
    },
    {
        "label": "ConditionClause",
        "kind": 6,
        "importPath": "models.ConditionClause",
        "description": "models.ConditionClause",
        "peekOfCode": "class ConditionClause:\n    \"\"\"Represents a single condition clause inside a ConditionalStatement.\"\"\"\n    Left: str = \"\"\n    Operator: str = \"\"\n    Right: str = \"\"\n    @property\n    def Clause(self) -> str:\n        \"\"\"Dynamically generates the clause as 'Left Operator Right'.\"\"\"\n        return f\"{self.Left} {self.Operator} {self.Right}\".strip()\n    @property",
        "detail": "models.ConditionClause",
        "documentation": {}
    },
    {
        "label": "Flow",
        "kind": 6,
        "importPath": "models.Flow",
        "description": "models.Flow",
        "peekOfCode": "class Flow:\n    \"\"\"\n    Represents a COBOL PROCEDURE DIVISION flow.\n    Contains a list of executed statements.\n    \"\"\"\n    Name: str = \"\"\n    Input: Dict = field(default_factory=dict)\n    Output: Dict = field(default_factory=dict)\n    Statements: List[\"Statement\"] = field(default_factory=list)\n    def addSentence(self, statement: \"Statement\"):",
        "detail": "models.Flow",
        "documentation": {}
    },
    {
        "label": "Statement",
        "kind": 6,
        "importPath": "models.Statement",
        "description": "models.Statement",
        "peekOfCode": "class Statement:\n    \"\"\"Base class for all COBOL statements.\"\"\"\n    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    type: StatementType = StatementType.OTHER\n    methodName: str = \"\"\n    def to_json(self):\n        return {\n            \"id\": self.id,\n            \"type\": self.type.name \n        }",
        "detail": "models.Statement",
        "documentation": {}
    },
    {
        "label": "StatementType",
        "kind": 6,
        "importPath": "models.StatementType",
        "description": "models.StatementType",
        "peekOfCode": "class StatementType(Enum):\n    ASSIGN = \"ASSIGN\"\n    CALL = \"CALL\"\n    CONDITION = \"CONDITION\"\n    CICS = \"CICS\"\n    OTHER = \"OTHER\"",
        "detail": "models.StatementType",
        "documentation": {}
    },
    {
        "label": "StaticAnalysis",
        "kind": 6,
        "importPath": "models.StaticAnalysis",
        "description": "models.StaticAnalysis",
        "peekOfCode": "class StaticAnalysis:\n    ProgramId: str = \"\"\n    Author: str = \"\"\n    Installation: str = \"\"\n    DateWritten: str = None\n    Compiled: str = None\n    Security: str = None\n    Flow: List[\"Flow\"] = field(default_factory=list) \n    DataStructures: List[dict] = field(default_factory=list)\n    def addFlow(self, flow: \"Flow\"):",
        "detail": "models.StaticAnalysis",
        "documentation": {}
    },
    {
        "label": "AssignStatement",
        "kind": 6,
        "importPath": "models.AssignStatement",
        "description": "models.AssignStatement",
        "peekOfCode": "class AssignStatement(Statement):\n    \"\"\"Represents a COBOL MOVE statement.\"\"\"\n    AssignFrom: str = \"\"\n    AssignTo: str = \"\"\n    def __post_init__(self):\n        self.type = StatementType.ASSIGN\n    @property\n    def raw(self) -> str:\n        \"\"\"Returns the assignment operation in string format.\"\"\"\n        return f\"{self.AssignFrom} = {self.AssignTo}\"",
        "detail": "models.AssignStatement",
        "documentation": {}
    },
    {
        "label": "ConditionalStatement",
        "kind": 6,
        "importPath": "models.ConditionalStatement",
        "description": "models.ConditionalStatement",
        "peekOfCode": "class ConditionalStatement(Statement):\n    \"\"\"Represents a conditional statement (IF condition) in COBOL code.\"\"\"\n    conditionClauses: List[\"ConditionClause\"] = field(default_factory=list)\n    TrueStatements: List[\"Statement\"] = field(default_factory=list)\n    FalseStatements: List[\"Statement\"] = field(default_factory=list)\n    def __post_init__(self):\n        self.type = StatementType.CONDITION\n    def addClause(self, clause):\n        \"\"\"Adds a condition clause to the statement.\"\"\"\n        if isinstance(clause, ConditionClause):",
        "detail": "models.ConditionalStatement",
        "documentation": {}
    },
    {
        "label": "CallStatement",
        "kind": 6,
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "peekOfCode": "class CallStatement(Statement):\n    \"\"\"Represents a COBOL PERFORM, CALL, or EXEC CICS statement.\"\"\"\n    Internal: bool = True  # True = PERFORM, False = CALL\n    Statements: List[\"Statement\"] = field(default_factory=list)  #  sub-statements  CICS\n    def __post_init__(self):\n        self.type = StatementType.CALL\n    @property\n    def raw(self) -> str:\n        \"\"\"Returns the raw execution string.\"\"\"\n        call_type = \"Perform\" if self.Internal else \"Call\"",
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "CallCicsStatement",
        "kind": 6,
        "importPath": "models.CallStatement",
        "description": "models.CallStatement",
        "peekOfCode": "class CallCicsStatement(Statement):\n    \"\"\"Represents a COBOL EXEC CICS statement.\"\"\"\n    Statements: List[\"Statement\"] = field(default_factory=list)  #  sub-statements  CICS\n    def __post_init__(self):\n        self.type = StatementType.CICS\n    @property\n    def raw(self) -> str:\n        \"\"\"Returns the full EXEC CICS command.\"\"\"\n        params = \" \".join(statement.raw for statement in self.Statements)\n        return f\"EXEC CICS {self.methodName} {params}\"",
        "detail": "models.CallStatement",
        "documentation": {}
    },
    {
        "label": "ContextInfoHelper",
        "kind": 6,
        "importPath": "to be deleted.helpers.ContextInfoHelper",
        "description": "to be deleted.helpers.ContextInfoHelper",
        "peekOfCode": "class ContextInfoHelper:\n    \"\"\"\n    Helper class for working with context objects.\n    Provides utility methods to extract and manipulate child nodes.\n    \"\"\"\n    @staticmethod\n    def get_children(ctx) -> List:\n        \"\"\"\n        Returns a list of all child nodes of the given context.\n        :param ctx: The context object.",
        "detail": "to be deleted.helpers.ContextInfoHelper",
        "documentation": {}
    },
    {
        "label": "get_children",
        "kind": 2,
        "importPath": "to be deleted.helpers.ContextInfo",
        "description": "to be deleted.helpers.ContextInfo",
        "peekOfCode": "def get_children(ctx) -> List:\n    \"\"\"\n           nodes  context.\n    :param ctx:   context.\n    :return:   child nodes.\n    \"\"\"\n    return list(ctx.getChildren())\ndef print_child(ctx) -> None:\n    \"\"\"\n      text   context.",
        "detail": "to be deleted.helpers.ContextInfo",
        "documentation": {}
    },
    {
        "label": "print_child",
        "kind": 2,
        "importPath": "to be deleted.helpers.ContextInfo",
        "description": "to be deleted.helpers.ContextInfo",
        "peekOfCode": "def print_child(ctx) -> None:\n    \"\"\"\n      text   context.\n    :param ctx:   context.\n    \"\"\"\n    logger.info(ctx.getText())\ndef get_child_text(ctx, idx: int) -> Optional[str]:\n    \"\"\"\n      text  child node   .\n    :param ctx:   context.",
        "detail": "to be deleted.helpers.ContextInfo",
        "documentation": {}
    },
    {
        "label": "get_child_text",
        "kind": 2,
        "importPath": "to be deleted.helpers.ContextInfo",
        "description": "to be deleted.helpers.ContextInfo",
        "peekOfCode": "def get_child_text(ctx, idx: int) -> Optional[str]:\n    \"\"\"\n      text  child node   .\n    :param ctx:   context.\n    :param idx:    child node.\n    :return:  text  child node  None      .\n    \"\"\"\n    try:\n        return ctx.getChild(idx).getText()\n    except (IndexError, AttributeError):",
        "detail": "to be deleted.helpers.ContextInfo",
        "documentation": {}
    },
    {
        "label": "get_child_concatenated_text",
        "kind": 2,
        "importPath": "to be deleted.helpers.ContextInfo",
        "description": "to be deleted.helpers.ContextInfo",
        "peekOfCode": "def get_child_concatenated_text(ctx, idx: int) -> str:\n    \"\"\"\n      concatenated text   child nodes   child node.\n    :param ctx:   context.\n    :param idx:    child node.\n    :return: Concatenated text   ,   space.\n    \"\"\"\n    try:\n        ch = ctx.getChild(idx)\n        if ch.getChildCount() == 0:  #    ,     text",
        "detail": "to be deleted.helpers.ContextInfo",
        "documentation": {}
    },
    {
        "label": "print_class_name",
        "kind": 2,
        "importPath": "to be deleted.helpers.ContextInfo",
        "description": "to be deleted.helpers.ContextInfo",
        "peekOfCode": "def print_class_name(obj):\n    \"\"\"\n    Debugging utility:       .\n    :param obj:    .\n    \"\"\"\n    logger.info(obj.__class__.__name__)",
        "detail": "to be deleted.helpers.ContextInfo",
        "documentation": {}
    },
    {
        "label": "ParseAssignStatements",
        "kind": 6,
        "importPath": "to be deleted.parsers.ParseAssignStatements",
        "description": "to be deleted.parsers.ParseAssignStatements",
        "peekOfCode": "class ParseAssignStatements:\n    \"\"\"\n    Parses MOVE statements inside PROCEDURE DIVISION.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the assignment statement parser.\"\"\"\n        pass\n    def visitMoveStatementContext(self, ctx):\n        \"\"\"Parses a MOVE statement and returns an AssignStatement.\"\"\"\n        logger.info(\"-------visitMoveStatementContext-----------\")",
        "detail": "to be deleted.parsers.ParseAssignStatements",
        "documentation": {}
    },
    {
        "label": "ParseCallStatements",
        "kind": 6,
        "importPath": "to be deleted.parsers.ParseCallStatements",
        "description": "to be deleted.parsers.ParseCallStatements",
        "peekOfCode": "class ParseCallStatements:\n    \"\"\"\n    Parses CALL and PERFORM statements inside PROCEDURE DIVISION.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the call statement parser.\"\"\"\n        pass\n    def visitPerformStatementContext(self, ctx):\n        \"\"\"Parses a PERFORM statement and returns a CallStatement.\"\"\"\n        logger.info(\"-------visitPerformStatementContext-----------\")",
        "detail": "to be deleted.parsers.ParseCallStatements",
        "documentation": {}
    },
    {
        "label": "ParseConditionalStatements",
        "kind": 6,
        "importPath": "to be deleted.parsers.ParseConditionalStatements",
        "description": "to be deleted.parsers.ParseConditionalStatements",
        "peekOfCode": "class ParseConditionalStatements:\n    \"\"\"\n    Responsible for parsing conditional (IF) statements inside COBOL PROCEDURE DIVISION.\n    \"\"\"\n    def visitIfStatementContext(self, ctx):\n        \"\"\"\n        Parses an IF statement, extracting the condition and its associated statements.\n        :param ctx: The parse tree context for IfStatement.\n        :return: A fully constructed ConditionalStatement object.\n        \"\"\"",
        "detail": "to be deleted.parsers.ParseConditionalStatements",
        "documentation": {}
    },
    {
        "label": "ParseStatements",
        "kind": 6,
        "importPath": "to be deleted.parsers.ParseStatements",
        "description": "to be deleted.parsers.ParseStatements",
        "peekOfCode": "class ParseStatements:\n    \"\"\"\n    Parses individual statements (MOVE, PERFORM, IF, etc.) inside PROCEDURE DIVISION.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the statement parser.\"\"\"\n        self.call_parser = ParseCallStatements()\n        self.assign_parser = ParseAssignStatements()\n        self.conditional_parser = ParseConditionalStatements()\n    def visitStatementContext(self, ctx):",
        "detail": "to be deleted.parsers.ParseStatements",
        "documentation": {}
    },
    {
        "label": "create_output_dir",
        "kind": 2,
        "importPath": "to be deleted.parsers.CobolParser",
        "description": "to be deleted.parsers.CobolParser",
        "peekOfCode": "def create_output_dir(output_dir=\"output\"):\n    \"\"\"        \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    return output_dir\ndef parse_cobol_file(file_path):\n    \"\"\"   COBOL        \"\"\"\n    input_stream = FileStream(file_path, encoding=\"utf-8\")\n    lexer = Cobol85Lexer(input_stream)\n    token_stream = CommonTokenStream(lexer)\n    parser = Cobol85Parser(token_stream)",
        "detail": "to be deleted.parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "parse_cobol_file",
        "kind": 2,
        "importPath": "to be deleted.parsers.CobolParser",
        "description": "to be deleted.parsers.CobolParser",
        "peekOfCode": "def parse_cobol_file(file_path):\n    \"\"\"   COBOL        \"\"\"\n    input_stream = FileStream(file_path, encoding=\"utf-8\")\n    lexer = Cobol85Lexer(input_stream)\n    token_stream = CommonTokenStream(lexer)\n    parser = Cobol85Parser(token_stream)\n    tree = parser.startRule()\n    return tree\ndef analyze_tree(tree):\n    \"\"\"   visitors       \"\"\"",
        "detail": "to be deleted.parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "analyze_tree",
        "kind": 2,
        "importPath": "to be deleted.parsers.CobolParser",
        "description": "to be deleted.parsers.CobolParser",
        "peekOfCode": "def analyze_tree(tree):\n    \"\"\"   visitors       \"\"\"\n    if tree:\n        pid = ParseIdentificationDivision()\n        static_analysis = parse_identification_division(ctx)\n        pd = ParseProcedureDivision()\n        pid.visit(tree)  #  Identification Division\n        static_analysis = pd.visit(tree)  #  Procedure Division\n        pid.staticAnalysis.Flow = pd.staticAnalysis.Flow\n        return pid.staticAnalysis",
        "detail": "to be deleted.parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "save_analysis_to_file",
        "kind": 2,
        "importPath": "to be deleted.parsers.CobolParser",
        "description": "to be deleted.parsers.CobolParser",
        "peekOfCode": "def save_analysis_to_file(static_analysis, file_path, output_dir=\"output\"):\n    \"\"\"       JSON  \"\"\"\n    file_name = os.path.basename(file_path)\n    file_name_without_ext = os.path.splitext(file_name)[0]\n    output_file = os.path.join(output_dir, f\"{file_name_without_ext}.json\")\n    json_output = static_analysis.to_json()\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(json_output)\n    print(f\"  : {output_file}\")\ndef generate_diagrams(static_analysis):",
        "detail": "to be deleted.parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "generate_diagrams",
        "kind": 2,
        "importPath": "to be deleted.parsers.CobolParser",
        "description": "to be deleted.parsers.CobolParser",
        "peekOfCode": "def generate_diagrams(static_analysis):\n    \"\"\"  Flowchart  BPMN  \"\"\"\n    if static_analysis:\n        diagram = FlowChartGenerator()\n        diagram.genrateDiagram(static_analysis, \"RECEIVE-OPTION\")\n        # bpmn = BPMNGenerator()\n        # bpmn.generate_bpmn_from_json(static_analysis, flow_name=\"00000-MAIN\", output_file=\"diagram.bpmn\")\ndef process_cobol_file(file_path, output_dir=\"output\"):\n    \"\"\"         \"\"\"\n    create_output_dir(output_dir)",
        "detail": "to be deleted.parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "process_cobol_file",
        "kind": 2,
        "importPath": "to be deleted.parsers.CobolParser",
        "description": "to be deleted.parsers.CobolParser",
        "peekOfCode": "def process_cobol_file(file_path, output_dir=\"output\"):\n    \"\"\"         \"\"\"\n    create_output_dir(output_dir)\n    tree = parse_cobol_file(file_path)\n    static_analysis = analyze_tree(tree)\n    if static_analysis:\n        save_analysis_to_file(static_analysis, file_path, output_dir)\n        generate_diagrams(static_analysis)",
        "detail": "to be deleted.parsers.CobolParser",
        "documentation": {}
    },
    {
        "label": "visit_procedure_division",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_procedure_division(ctx):\n    \"\"\"\n      PROCEDURE DIVISION     .\n    \"\"\"\n    logger.info(\"-------visit_procedure_division-----------\")\n    static_analysis = StaticAnalysis()\n    for child in get_children(ctx):\n        if isinstance(child, Cobol85Parser.ProcedureDivisionBodyContext):\n            logger.info(\"===================================================\")\n            visit_procedure_division_body(child, static_analysis)",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_procedure_division_body",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_procedure_division_body(ctx, static_analysis):\n    \"\"\"\n      ProcedureDivisionBody    .\n    \"\"\"\n    logger.info(\"-------visit_procedure_division_body-----------\")\n    for child in get_children(ctx):\n        if isinstance(child, Cobol85Parser.ParagraphsContext):\n            visit_paragraphs_context(child, static_analysis)\ndef visit_paragraphs_context(ctx, static_analysis):\n    \"\"\"",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_paragraphs_context",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_paragraphs_context(ctx, static_analysis):\n    \"\"\"\n         PROCEDURE DIVISION.\n    \"\"\"\n    logger.info(\"-------visit_paragraphs_context-----------\")\n    for child in get_children(ctx):\n        if isinstance(child, Cobol85Parser.ParagraphContext):\n            visit_paragraph_context(child, static_analysis)\ndef visit_paragraph_context(ctx, static_analysis):\n    \"\"\"",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_paragraph_context",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_paragraph_context(ctx, static_analysis):\n    \"\"\"\n           .\n    \"\"\"\n    logger.info(\"-------visit_paragraph_context-----------\")\n    flow = Flow()\n    for child in get_children(ctx):\n        if isinstance(child, Cobol85Parser.ParagraphNameContext):\n            flow.Name = visit_paragraph_name_context(child)\n        if isinstance(child, Cobol85Parser.SentenceContext):",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_paragraph_name_context",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_paragraph_name_context(ctx):\n    \"\"\"\n        .\n    \"\"\"\n    logger.info(\"-------visit_paragraph_name_context-----------\")\n    return ctx.getChild(0).getText()\ndef visit_sentence_context(ctx, flow):\n    \"\"\"\n       (sentences)  .\n    \"\"\"",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_sentence_context",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_sentence_context(ctx, flow):\n    \"\"\"\n       (sentences)  .\n    \"\"\"\n    logger.info(\"-------visit_sentence_context-----------\")\n    for child in get_children(ctx):\n        if isinstance(child, Cobol85Parser.StatementContext):\n            visit_statement_context(child, flow)\ndef visit_statement_context(ctx, flow):\n    \"\"\"",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_statement_context",
        "kind": 2,
        "importPath": "to be deleted.parsers.ProcedureDivisionParser",
        "description": "to be deleted.parsers.ProcedureDivisionParser",
        "peekOfCode": "def visit_statement_context(ctx, flow):\n    \"\"\"\n      parser  statements      .\n    \"\"\"\n    statement_parser = ParseStatements()\n    statement = statement_parser.visitStatementContext(ctx)\n    if statement is not None:\n        flow.addSentence(statement)",
        "detail": "to be deleted.parsers.ProcedureDivisionParser",
        "documentation": {}
    },
    {
        "label": "parse_identification_division",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def parse_identification_division(ctx):\n    \"\"\"\n      IDENTIFICATION DIVISION    .\n    \"\"\"\n    logger.info(\"Processing IDENTIFICATION DIVISION...\")\n    static_analysis = StaticAnalysis()\n    for child in ctx.children:\n        if isinstance(child, Cobol85Parser.ProgramIdParagraphContext):\n            static_analysis.ProgramId = visit_program_id_paragraph(child)\n        if isinstance(child, Cobol85Parser.IdentificationDivisionBodyContext):",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "process_identification_body",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def process_identification_body(ctx, static_analysis):\n    \"\"\"\n      IdentificationDivisionBody     Author, Installation, DateWritten, Security.\n    \"\"\"\n    for sub_child in ctx.children:\n        if isinstance(sub_child, Cobol85Parser.AuthorParagraphContext):\n            static_analysis.Author = visit_author_paragraph(sub_child)\n        elif isinstance(sub_child, Cobol85Parser.InstallationParagraphContext):\n            static_analysis.Installation = visit_installation_paragraph(sub_child)\n        elif isinstance(sub_child, Cobol85Parser.DateWrittenParagraphContext):",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_program_id_paragraph",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def visit_program_id_paragraph(ctx):\n    \"\"\"\n      Program-ID    context.\n    \"\"\"\n    logger.info(f\"\\t\\t{ctx.__class__.__name__}\")\n    return ctx.getChild(2).getText().strip() if ctx.getChildCount() > 2 else \"\"\ndef visit_author_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_installation_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_author_paragraph",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def visit_author_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_installation_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_date_written_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_installation_paragraph",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def visit_installation_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_date_written_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_date_written_paragraph",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def visit_date_written_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"\n    parts = line.split(\".\", 1)\n    value = parts[1].strip() if len(parts) > 1 else \"\"",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "visit_security_paragraph",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"\n    parts = line.split(\".\", 1)\n    value = parts[1].strip() if len(parts) > 1 else \"\"\n    return value[:-1] if value.endswith(\".\") else value",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "extract_value_from_identification_line",
        "kind": 2,
        "importPath": "to be deleted.parsers.IdentificationDivisionParser",
        "description": "to be deleted.parsers.IdentificationDivisionParser",
        "peekOfCode": "def extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"\n    parts = line.split(\".\", 1)\n    value = parts[1].strip() if len(parts) > 1 else \"\"\n    return value[:-1] if value.endswith(\".\") else value",
        "detail": "to be deleted.parsers.IdentificationDivisionParser",
        "documentation": {}
    },
    {
        "label": "CobolParser",
        "kind": 6,
        "importPath": "to be deleted.CobolParser",
        "description": "to be deleted.CobolParser",
        "peekOfCode": "class CobolParser:\n    def __init__(self, output_dir=\"output\"):\n        self.tree = None\n        self.visitor = CobolVisitor()\n        self.flow_analyzer = FlowAnalyzer()\n        self.output_dir = output_dir  #   \n        #   output directory   \n        os.makedirs(self.output_dir, exist_ok=True)\n    def parse_file(self, file_path):\n        input_stream = FileStream(file_path, encoding=\"utf-8\")",
        "detail": "to be deleted.CobolParser",
        "documentation": {}
    },
    {
        "label": "CobolVisitor",
        "kind": 6,
        "importPath": "to be deleted.CobolVisitor",
        "description": "to be deleted.CobolVisitor",
        "peekOfCode": "class CobolVisitor(Cobol85Visitor):\n    def __init__(self):\n        #    entry points    \n        self.entry_points = []           #  entry points\n        self.entry_inputs = {}           # { entry: [input1, input2, ...] }\n        self.entry_outputs = {}          # { entry: [output1, output2, ...] }\n        self.calls = {}                  # { entry: [call_obj, ...] } ()\n        #    Flow (     \"Calls\"   JSON)\n        self.flow_calls = {}             # { entry: [call_obj, ...] }\n        self.current_entry = None",
        "detail": "to be deleted.CobolVisitor",
        "documentation": {}
    },
    {
        "label": "FlowAnalyzer",
        "kind": 6,
        "importPath": "to be deleted.FlowAnalyzer",
        "description": "to be deleted.FlowAnalyzer",
        "peekOfCode": "class FlowAnalyzer(Cobol85Visitor):\n    def __init__(self):\n        super().__init__()\n        self.flow_graph = {}  # {entry_point: [next_steps]}\n        self.outputs = {}     # {entry_point: [displayed_outputs]}\n        self.current_entry = None\n    def add_edge(self, source, target):\n        \"\"\"  edge  flow graph.\"\"\"\n        if source in self.flow_graph:\n            self.flow_graph[source].append(target)",
        "detail": "to be deleted.FlowAnalyzer",
        "documentation": {}
    },
    {
        "label": "FlowChartGenerator",
        "kind": 6,
        "importPath": "to be deleted.FlowChartGenerator",
        "description": "to be deleted.FlowChartGenerator",
        "peekOfCode": "class FlowChartGenerator:\n    def __init__(self):\n        pass\n    def process_sentence(self, sentence, indent=0):\n        \"\"\"\n          \"Sentence\"        PlantUML.\n        \"\"\"\n        lines = []\n        prefix = \"  \" * indent\n        stype = sentence.get(\"type\", \"\")",
        "detail": "to be deleted.FlowChartGenerator",
        "documentation": {}
    },
    {
        "label": "BPMNGenerator",
        "kind": 6,
        "importPath": "to be deleted.GenerateBPMN",
        "description": "to be deleted.GenerateBPMN",
        "peekOfCode": "class BPMNGenerator:\n    def add_task(self, process, name):\n        task_id, _ = process.add_task_to_diagram(name)\n        return task_id\n    def add_gateway(self, process, name):\n        gateway_id, _ = process.add_exclusive_gateway_to_diagram(name)\n        return gateway_id\n    def add_flow(self, process, source, target, flow_name=None):\n        process.add_sequence_flow_to_diagram(source, target, flow_name)\n    def process_sentence(self, process, sentence):",
        "detail": "to be deleted.GenerateBPMN",
        "documentation": {}
    },
    {
        "label": "ParseIdentificationDivision",
        "kind": 6,
        "importPath": "to be deleted.IdentificationDivision",
        "description": "to be deleted.IdentificationDivision",
        "peekOfCode": "class ParseIdentificationDivision(Cobol85Visitor):\n    def __init__(self):\n        self.staticAnalysis = StaticAnalysis()\n    # --- Identification Division analysis ---\n    def visitIdentificationDivision(self, ctx):\n        #   \n        static_analysis = StaticAnalysis()\n        #   `visit`      \n        for child in ctx.children:\n            if isinstance(child, Cobol85Parser.ProgramIdParagraphContext):",
        "detail": "to be deleted.IdentificationDivision",
        "documentation": {}
    },
    {
        "label": "process_files",
        "kind": 2,
        "importPath": "to be deleted.main",
        "description": "to be deleted.main",
        "peekOfCode": "def process_files(file_pattern):\n    \"\"\"\n        COBOL    file_pattern.\n    :param file_pattern:     wildcard (.. \"*.cbl\").\n    \"\"\"\n    #       pattern\n    files = glob.glob(file_pattern)\n    if not files:\n        print(f\"        : {file_pattern}\")\n        return",
        "detail": "to be deleted.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "to be deleted.main",
        "description": "to be deleted.main",
        "peekOfCode": "def main():\n    \"\"\"\n           parser,  input   .\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"COBOL Static Analysis Parser\")\n    #  argument      wildcard pattern\n    parser.add_argument(\"file_pattern\", help=\"  COBOL  wildcard pattern (.. '*.cbl')\")\n    #     CLI\n    args = parser.parse_args()\n    #    path    ",
        "detail": "to be deleted.main",
        "documentation": {}
    },
    {
        "label": "ParseProcedureDivision",
        "kind": 6,
        "importPath": "to be deleted.ParseProcedureDivision copy",
        "description": "to be deleted.ParseProcedureDivision copy",
        "peekOfCode": "class ParseProcedureDivision(Cobol85Visitor):\n    \"\"\"\n    Visitor class for parsing the PROCEDURE DIVISION of a COBOL program.\n    Extracts flows, statements, and method calls.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the visitor with an empty StaticAnalysis object.\"\"\"\n        self.staticAnalysis = StaticAnalysis()\n    def visitProcedureDivision(self, ctx):\n        \"\"\"",
        "detail": "to be deleted.ParseProcedureDivision copy",
        "documentation": {}
    },
    {
        "label": "logger.info",
        "kind": 2,
        "importPath": "to be deleted.ParseProcedureDivision copy",
        "description": "to be deleted.ParseProcedureDivision copy",
        "peekOfCode": "def logger.info(message):\n    if DEBUG_MODE:\n        print(message)\nclass ParseProcedureDivision(Cobol85Visitor):\n    \"\"\"\n    Visitor class for parsing the PROCEDURE DIVISION of a COBOL program.\n    Extracts flows, statements, and method calls.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the visitor with an empty StaticAnalysis object.\"\"\"",
        "detail": "to be deleted.ParseProcedureDivision copy",
        "documentation": {}
    },
    {
        "label": "DEBUG_MODE",
        "kind": 5,
        "importPath": "to be deleted.ParseProcedureDivision copy",
        "description": "to be deleted.ParseProcedureDivision copy",
        "peekOfCode": "DEBUG_MODE = False  \ndef logger.info(message):\n    if DEBUG_MODE:\n        print(message)\nclass ParseProcedureDivision(Cobol85Visitor):\n    \"\"\"\n    Visitor class for parsing the PROCEDURE DIVISION of a COBOL program.\n    Extracts flows, statements, and method calls.\n    \"\"\"\n    def __init__(self):",
        "detail": "to be deleted.ParseProcedureDivision copy",
        "documentation": {}
    },
    {
        "label": "ParseProcedureDivision",
        "kind": 6,
        "importPath": "to be deleted.ParseProcedureDivision",
        "description": "to be deleted.ParseProcedureDivision",
        "peekOfCode": "class ParseProcedureDivision(Cobol85Visitor):\n    \"\"\"\n    Visitor class for parsing the PROCEDURE DIVISION of a COBOL program.\n    Extracts flows, statements, and method calls.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes the visitor with an empty StaticAnalysis object.\"\"\"\n        self.staticAnalysis = StaticAnalysis()\n    def visitProcedureDivision(self, ctx):\n        \"\"\"",
        "detail": "to be deleted.ParseProcedureDivision",
        "documentation": {}
    },
    {
        "label": "preprocess_cobol",
        "kind": 2,
        "importPath": "to be deleted.preprocess_cobol",
        "description": "to be deleted.preprocess_cobol",
        "peekOfCode": "def preprocess_cobol(file_path):\n    input_stream = FileStream(file_path, encoding=\"utf-8\")\n    lexer = Cobol85PreprocessorLexer(input_stream)\n    token_stream = CommonTokenStream(lexer)\n    parser = Cobol85PreprocessorParser(token_stream)\n    tree = parser.startRule()\n    visitor = CustomPreprocessorVisitor()\n    visitor.visit(tree)\nif __name__ == \"__main__\":\n    preprocess_cobol(\"./Samples/DOGEMAIN.cbl\")",
        "detail": "to be deleted.preprocess_cobol",
        "documentation": {}
    },
    {
        "label": "CustomPreprocessorVisitor",
        "kind": 6,
        "importPath": "to be deleted.PreprocessorVisitor",
        "description": "to be deleted.PreprocessorVisitor",
        "peekOfCode": "class CustomPreprocessorVisitor(Cobol85PreprocessorVisitor):\n    def visitCopyStatement(self, ctx: Cobol85PreprocessorParser.CopyStatementContext):\n        print(\" COPY statement:\", ctx.getText())\n        return self.visitChildren(ctx)\n    def visitReplaceStatement(self, ctx: Cobol85PreprocessorParser.ReplaceByStatementContext):\n        print(\" REPLACE statement:\", ctx.getText())\n        return self.visitChildren(ctx)",
        "detail": "to be deleted.PreprocessorVisitor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "logger",
        "description": "logger",
        "peekOfCode": "logger = logging.getLogger(\"StaticAnalysisLogger\")\nlogger.setLevel(logging.DEBUG) \n#  Handler (    )\nconsole_handler = logging.StreamHandler()\nfile_handler = logging.FileHandler(\"static_analysis.log\")\n#   format   \nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(formatter)\nfile_handler.setFormatter(formatter)\n#  handlers  logger",
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "logger",
        "description": "logger",
        "peekOfCode": "console_handler = logging.StreamHandler()\nfile_handler = logging.FileHandler(\"static_analysis.log\")\n#   format   \nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(formatter)\nfile_handler.setFormatter(formatter)\n#  handlers  logger\n#logger.addHandler(console_handler)\nlogger.addHandler(file_handler)",
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "logger",
        "description": "logger",
        "peekOfCode": "file_handler = logging.FileHandler(\"static_analysis.log\")\n#   format   \nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(formatter)\nfile_handler.setFormatter(formatter)\n#  handlers  logger\n#logger.addHandler(console_handler)\nlogger.addHandler(file_handler)",
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": "logger",
        "description": "logger",
        "peekOfCode": "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(formatter)\nfile_handler.setFormatter(formatter)\n#  handlers  logger\n#logger.addHandler(console_handler)\nlogger.addHandler(file_handler)",
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "get_children",
        "kind": 2,
        "importPath": "context_info",
        "description": "context_info",
        "peekOfCode": "def get_children(ctx) -> List:\n    \"\"\"\n           nodes  context.\n    :param ctx:   context.\n    :return:   child nodes.\n    \"\"\"\n    return list(ctx.getChildren())\ndef print_child(ctx) -> None:\n    \"\"\"\n      text   context.",
        "detail": "context_info",
        "documentation": {}
    },
    {
        "label": "print_child",
        "kind": 2,
        "importPath": "context_info",
        "description": "context_info",
        "peekOfCode": "def print_child(ctx) -> None:\n    \"\"\"\n      text   context.\n    :param ctx:   context.\n    \"\"\"\n    logger.info(ctx.getText())\ndef get_child_text(ctx, idx: int) -> Optional[str]:\n    \"\"\"\n      text  child node   .\n    :param ctx:   context.",
        "detail": "context_info",
        "documentation": {}
    },
    {
        "label": "get_child_text",
        "kind": 2,
        "importPath": "context_info",
        "description": "context_info",
        "peekOfCode": "def get_child_text(ctx, idx: int) -> Optional[str]:\n    \"\"\"\n      text  child node   .\n    :param ctx:   context.\n    :param idx:    child node.\n    :return:  text  child node  None      .\n    \"\"\"\n    try:\n        return ctx.getChild(idx).getText()\n    except (IndexError, AttributeError):",
        "detail": "context_info",
        "documentation": {}
    },
    {
        "label": "get_child_concatenated_text",
        "kind": 2,
        "importPath": "context_info",
        "description": "context_info",
        "peekOfCode": "def get_child_concatenated_text(ctx, idx: int) -> str:\n    \"\"\"\n      concatenated text   child nodes   child node.\n    :param ctx:   context.\n    :param idx:    child node.\n    :return: Concatenated text   ,   space.\n    \"\"\"\n    try:\n        ch = ctx.getChild(idx)\n        if ch.getChildCount() == 0:  #    ,     text",
        "detail": "context_info",
        "documentation": {}
    },
    {
        "label": "print_class_name",
        "kind": 2,
        "importPath": "context_info",
        "description": "context_info",
        "peekOfCode": "def print_class_name(obj):\n    \"\"\"\n    Debugging utility:       .\n    :param obj:    .\n    \"\"\"\n    logger.info(obj.__class__.__name__)",
        "detail": "context_info",
        "documentation": {}
    },
    {
        "label": "process_files",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def process_files(file_pattern):\n    \"\"\"\n        COBOL    file_pattern.\n    :param file_pattern:     wildcard (.. \"*.cbl\").\n    \"\"\"\n    files = glob.glob(file_pattern) if not os.path.isfile(file_pattern) else [file_pattern]\n    if not files:\n        print(f\"        : {file_pattern}\")\n        return\n    for file_path in files:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    \"\"\"\n           parser,  input   .\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"COBOL Static Analysis Parser\")\n    #  argument      wildcard pattern\n    parser.add_argument(\"file_pattern\", help=\"  COBOL  wildcard pattern (.. '*.cbl')\")\n    # args = parser.parse_args()\n    # process_files(args.file_pattern)\n    process_files(\".\\\\Samples\\\\DOGE*.cbl\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "create_output_dir",
        "kind": 2,
        "importPath": "parse_cobol",
        "description": "parse_cobol",
        "peekOfCode": "def create_output_dir(output_dir=\"output\"):\n    \"\"\"        \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    return output_dir\n# def parse_cobol_file(file_path):\n#     \"\"\"   COBOL        \"\"\"\n#     logger.info(f\"Processing file {file_path}...\")\n#     input_stream = FileStream(file_path, encoding=\"utf-8\")\n#     lexer = Cobol85Lexer(input_stream)\n#     token_stream = CommonTokenStream(lexer)",
        "detail": "parse_cobol",
        "documentation": {}
    },
    {
        "label": "save_analysis_to_file",
        "kind": 2,
        "importPath": "parse_cobol",
        "description": "parse_cobol",
        "peekOfCode": "def save_analysis_to_file(static_analysis, file_path, output_dir=\"output\"):\n    \"\"\"       JSON  \"\"\"\n    logger.info(f\"Saving file {file_path}...\")\n    file_name = os.path.basename(file_path)\n    file_name_without_ext = os.path.splitext(file_name)[0]\n    output_file = os.path.join(output_dir, f\"{file_name_without_ext}.json\")\n    json_output = static_analysis.to_json()\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(json_output)\n    print(f\"  : {output_file}\")",
        "detail": "parse_cobol",
        "documentation": {}
    },
    {
        "label": "generate_diagrams",
        "kind": 2,
        "importPath": "parse_cobol",
        "description": "parse_cobol",
        "peekOfCode": "def generate_diagrams(static_analysis):\n    \"\"\"  Flowchart  BPMN  \"\"\"\n    pass\n    # if static_analysis:\n        # diagram = FlowChartGenerator()\n        # diagram.genrateDiagram(static_analysis, \"RECEIVE-OPTION\")\ndef process_cobol_file(file_path, output_dir=\"output\"):\n    \"\"\"         \"\"\"\n    logger.info(f\"Processing file {file_path}...\")\n    input_stream = FileStream(file_path, encoding=\"utf-8\")",
        "detail": "parse_cobol",
        "documentation": {}
    },
    {
        "label": "process_cobol_file",
        "kind": 2,
        "importPath": "parse_cobol",
        "description": "parse_cobol",
        "peekOfCode": "def process_cobol_file(file_path, output_dir=\"output\"):\n    \"\"\"         \"\"\"\n    logger.info(f\"Processing file {file_path}...\")\n    input_stream = FileStream(file_path, encoding=\"utf-8\")\n    lexer = Cobol85Lexer(input_stream)\n    token_stream = CommonTokenStream(lexer)\n    parser = Cobol85Parser(token_stream)\n    # error_listener = CustomErrorListener()\n    # parser.removeErrorListeners()  #   default listener\n    # parser.addErrorListener(error_listener)    ",
        "detail": "parse_cobol",
        "documentation": {}
    },
    {
        "label": "find_section",
        "kind": 2,
        "importPath": "parse_cobol",
        "description": "parse_cobol",
        "peekOfCode": "def find_section(section_class, ctx):\n    \"\"\"\n       WorkingStorageSection     parse tree.\n    \"\"\"\n    if ctx is None:\n        return None\n    #      WorkingStorageSection, \n    if isinstance(ctx, section_class):\n        return ctx\n    #      ",
        "detail": "parse_cobol",
        "documentation": {}
    },
    {
        "label": "parse_identification_division",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def parse_identification_division(ctx):\n    \"\"\"\n      IDENTIFICATION DIVISION    .\n    \"\"\"\n    logger.info(\"Processing IDENTIFICATION DIVISION...\")\n    static_analysis = StaticAnalysis()\n    logger.info(f\"\\t{ctx.__class__.__name__}\")\n    for child in ctx.children:\n        logger.info(f\"\\t{child.__class__.__name__}\")\n        if isinstance(child, Cobol85Parser.ProgramIdParagraphContext):",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "process_identification_body",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def process_identification_body(ctx, static_analysis):\n    \"\"\"\n      IdentificationDivisionBody     Author, Installation, DateWritten, Security.\n    \"\"\"\n    for sub_child in ctx.children:\n        if isinstance(sub_child, Cobol85Parser.AuthorParagraphContext):\n            static_analysis.Author = visit_author_paragraph(sub_child)\n        elif isinstance(sub_child, Cobol85Parser.InstallationParagraphContext):\n            static_analysis.Installation = visit_installation_paragraph(sub_child)\n        elif isinstance(sub_child, Cobol85Parser.DateWrittenParagraphContext):",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "visit_program_id_paragraph",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def visit_program_id_paragraph(ctx):\n    \"\"\"\n      Program-ID    context.\n    \"\"\"\n    logger.info(f\"\\t\\t{ctx.__class__.__name__}\")\n    return ctx.getChild(2).getText().strip() if ctx.getChildCount() > 2 else \"\"\ndef visit_author_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_installation_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "visit_author_paragraph",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def visit_author_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_installation_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_date_written_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "visit_installation_paragraph",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def visit_installation_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_date_written_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "visit_date_written_paragraph",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def visit_date_written_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"\n    parts = line.split(\".\", 1)\n    value = parts[1].strip() if len(parts) > 1 else \"\"",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "visit_security_paragraph",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def visit_security_paragraph(ctx):\n    return extract_value_from_identification_line(ctx.getText().strip())\ndef extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"\n    parts = line.split(\".\", 1)\n    value = parts[1].strip() if len(parts) > 1 else \"\"\n    return value[:-1] if value.endswith(\".\") else value",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "extract_value_from_identification_line",
        "kind": 2,
        "importPath": "parse_identification_division",
        "description": "parse_identification_division",
        "peekOfCode": "def extract_value_from_identification_line(line):\n    \"\"\"\n           `.`  .\n    \"\"\"\n    parts = line.split(\".\", 1)\n    value = parts[1].strip() if len(parts) > 1 else \"\"\n    return value[:-1] if value.endswith(\".\") else value",
        "detail": "parse_identification_division",
        "documentation": {}
    },
    {
        "label": "parse_procedure_division",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def parse_procedure_division(ctx, static_analysis):\n    \"\"\"\n      PROCEDURE DIVISION     .\n    \"\"\"\n    logger.info(\"-------visit_procedure_division-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ProcedureDivisionBodyContext):\n            logger.info(\"===================================================\")\n            visit_procedure_division_body(child, static_analysis)\n    logger.info(\"-------End of ProcedureDivision-----------\")",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "visit_procedure_division_body",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def visit_procedure_division_body(ctx, static_analysis):\n    \"\"\"\n      ProcedureDivisionBody    .\n    \"\"\"\n    # logger.info(\"-------visit_procedure_division_body-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ParagraphsContext):\n            visit_paragraphs_context(child, static_analysis)\ndef visit_paragraphs_context(ctx, static_analysis):\n    \"\"\"",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "visit_paragraphs_context",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def visit_paragraphs_context(ctx, static_analysis):\n    \"\"\"\n         PROCEDURE DIVISION.\n    \"\"\"\n    # logger.info(\"-------visit_paragraphs_context-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ParagraphContext):\n            visit_paragraph_context(child, static_analysis)\ndef visit_paragraph_context(ctx, static_analysis):\n    \"\"\"",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "visit_paragraph_context",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def visit_paragraph_context(ctx, static_analysis):\n    \"\"\"\n           .\n    \"\"\"\n    # logger.info(\"-------visit_paragraph_context-----------\")\n    flow = Flow()\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ParagraphNameContext):\n            flow.Name = visit_paragraph_name_context(child)\n        if isinstance(child, Cobol85Parser.SentenceContext):",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "visit_paragraph_name_context",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def visit_paragraph_name_context(ctx):\n    \"\"\"\n        .\n    \"\"\"\n    # logger.info(\"-------visit_paragraph_name_context-----------\")\n    return ctx.getChild(0).getText()\ndef visit_sentence_context(ctx, flow):\n    \"\"\"\n       (sentences)  .\n    \"\"\"",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "visit_sentence_context",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def visit_sentence_context(ctx, flow):\n    \"\"\"\n       (sentences)  .\n    \"\"\"\n    # logger.info(\"-------visit_sentence_context-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.StatementContext):\n            visit_statement_context(child, flow)\ndef visit_statement_context(ctx, flow):\n    \"\"\"",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "visit_statement_context",
        "kind": 2,
        "importPath": "parse_procedure_division",
        "description": "parse_procedure_division",
        "peekOfCode": "def visit_statement_context(ctx, flow):\n    \"\"\"\n      parser  statements      .\n    \"\"\"\n    statement = parse_statements.parse_statement(ctx)\n    if statement is not None:\n        flow.addSentence(statement)",
        "detail": "parse_procedure_division",
        "documentation": {}
    },
    {
        "label": "parse_statement",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def parse_statement(ctx):\n    \"\"\"\n      Statement node     statement object.\n    \"\"\"\n    # logger.info(\"-------visitStatementContext-----------\")\n    statement_map = {\n        Cobol85Parser.MoveStatementContext: visit_move_statement_context,\n        Cobol85Parser.PerformStatementContext: visit_perform_statement_context,\n        Cobol85Parser.GobackStatementContext: visit_goback_statement_context,\n        Cobol85Parser.IfStatementContext: visit_if_statement_context,",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_if_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_if_statement_context(ctx):\n    \"\"\"   IF statement. \"\"\"\n    # logger.info(\"-------visitIfStatementContext-----------\")\n    conditional_statement = ConditionalStatement(methodName=f\"IF {context_info.get_child_concatenated_text(ctx, 1)}\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.IfThenContext):\n            visit_if_then_context(child, conditional_statement)\n        elif isinstance(child, Cobol85Parser.IfElseContext):\n            visit_if_else_context(child, conditional_statement)\n    return conditional_statement",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_if_then_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_if_then_context(ctx, conditional_statement):\n    \"\"\"   THEN   IF. \"\"\"\n    # logger.info(\"-------visitIfThenContext-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.CombinableConditionContext):\n            condition = visit_combinable_condition_context(child)\n            if condition:\n                conditional_statement.addClause(condition)\n        elif isinstance(child, Cobol85Parser.StatementContext):\n            statement = parse_statement(child)",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_if_else_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_if_else_context(ctx, conditional_statement):\n    \"\"\"   ELSE   IF. \"\"\"\n    # logger.info(\"-------visitIfElseContext-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.StatementContext):\n            statement = parse_statement(child)\n            if statement:\n                conditional_statement.addFalseStatement(statement)\n# ----------------------------------------------------\n# Conditions",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_combinable_condition_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_combinable_condition_context(ctx):\n    \"\"\"    (AND, OR). \"\"\"\n    # logger.info(\"-------visitCombinableConditionContext-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.SimpleConditionContext):\n            return visit_simple_condition_context(child)\n    return None\ndef visit_simple_condition_context(ctx):\n    \"\"\"     (.. X > 5). \"\"\"\n    # logger.info(\"-------visitSimpleConditionContext-----------\")",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_simple_condition_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_simple_condition_context(ctx):\n    \"\"\"     (.. X > 5). \"\"\"\n    # logger.info(\"-------visitSimpleConditionContext-----------\")\n    conditional_statement = ConditionalStatement(methodName=\"IF\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.RelationConditionContext):\n            clause = visit_relation_condition_context(child)\n            if clause:\n                conditional_statement.addClause(clause)\n    return conditional_statement",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_relation_condition_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_relation_condition_context(ctx):\n    \"\"\"    (.. X = Y). \"\"\"\n    # logger.info(\"-------visitRelationConditionContext-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.RelationArithmeticComparisonContext):\n            return visit_relation_arithmetic_comparison_context(child)\ndef visit_relation_arithmetic_comparison_context(ctx):\n    \"\"\"    (.. A > B). \"\"\"\n    # logger.info(\"-------visitRelationArithmeticComparisonContext-----------\")\n    return ConditionClause(",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_relation_arithmetic_comparison_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_relation_arithmetic_comparison_context(ctx):\n    \"\"\"    (.. A > B). \"\"\"\n    # logger.info(\"-------visitRelationArithmeticComparisonContext-----------\")\n    return ConditionClause(\n        Left=context_info.get_child_text(ctx, 0),\n        Operator=context_info.get_child_concatenated_text(ctx, 1),\n        Right=context_info.get_child_text(ctx, 2)\n    )\n# ----------------------------------------------------\n# MOVE Statements",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_move_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_move_statement_context(ctx):\n    \"\"\"   MOVE statement    AssignStatement. \"\"\"\n    # logger.info(\"-------visitMoveStatementContext-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.MoveToStatementContext):\n            move_sentence = visit_move_to_statement_context(child)\n            assignFrom = move_sentence.AssignFrom\n            assignTo = move_sentence.AssignTo\n            return AssignStatement(methodName=f\"Assign value to {assignTo}\", AssignFrom=assignFrom, AssignTo=assignTo)\n    return None",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_move_to_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_move_to_statement_context(ctx):\n    \"\"\"   MOVE TO   statement. \"\"\"\n    assignFrom = None\n    assignTo = None\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.IdentifierContext):\n            assignTo = visit_identifier_context(child)\n        elif isinstance(child, Cobol85Parser.MoveToSendingAreaContext):\n            assignFrom = visit_move_to_sending_area_context(child)\n    if assignFrom and assignTo:",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_identifier_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_identifier_context(ctx):\n    \"\"\"   text  identifier. \"\"\"\n    return ctx.getChild(0).getText() if ctx.getChildCount() > 0 else \"\"\ndef visit_move_to_sending_area_context(ctx):\n    \"\"\"   text  sending area. \"\"\"\n    return ctx.getChild(0).getText() if ctx.getChildCount() > 0 else \"\"\n# ----------------------------------------------------\n# PERFORM Statements\n# ----------------------------------------------------\ndef visit_perform_statement_context(ctx):",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_move_to_sending_area_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_move_to_sending_area_context(ctx):\n    \"\"\"   text  sending area. \"\"\"\n    return ctx.getChild(0).getText() if ctx.getChildCount() > 0 else \"\"\n# ----------------------------------------------------\n# PERFORM Statements\n# ----------------------------------------------------\ndef visit_perform_statement_context(ctx):\n    \"\"\"   PERFORM statement. \"\"\"\n    # logger.info(\"-------visitPerformStatementContext-----------\")\n    for child in context_info.get_children(ctx):",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_perform_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_perform_statement_context(ctx):\n    \"\"\"   PERFORM statement. \"\"\"\n    # logger.info(\"-------visitPerformStatementContext-----------\")\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.PerformProcedureStatementContext):\n            return visit_perform_procedure_statement_context(child)\n    return None\ndef visit_perform_procedure_statement_context(ctx):\n    \"\"\"       PERFORM. \"\"\"\n    return CallStatement(methodName=ctx.getText())",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_perform_procedure_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_perform_procedure_statement_context(ctx):\n    \"\"\"       PERFORM. \"\"\"\n    return CallStatement(methodName=ctx.getText())\n# ----------------------------------------------------\n# EXEC CICS Statements\n# ----------------------------------------------------\ndef visit_exec_cics_statement_context(ctx):\n    \"\"\"   EXEC CICS statement. \"\"\"\n    call_statement = CallCicsStatement()\n    for child in context_info.get_children(ctx):",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_exec_cics_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_exec_cics_statement_context(ctx):\n    \"\"\"   EXEC CICS statement. \"\"\"\n    call_statement = CallCicsStatement()\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ExecCicsCommandContext):\n            command_name, params = visit_exec_cics_command_context(child)\n            call_statement.methodName = command_name\n            call_statement.Statements.extend(params)\n    return call_statement\ndef visit_exec_cics_command_context(ctx):",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_exec_cics_command_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_exec_cics_command_context(ctx):\n    \"\"\"       EXEC CICS statement. \"\"\"\n    # context_info.print_class_name(ctx)\n    children = context_info.get_children(ctx)\n    if not children:\n        return \"\", []\n    command_name = children[0].getText()\n    params = [Statement(child.getText()) for child in children[1:]]\n    return command_name, params\n# ----------------------------------------------------",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "visit_goback_statement_context",
        "kind": 2,
        "importPath": "parse_statements",
        "description": "parse_statements",
        "peekOfCode": "def visit_goback_statement_context(ctx):\n    \"\"\"   GOBACK statement. \"\"\"\n    return CallStatement(methodName=\"GOBACK\")",
        "detail": "parse_statements",
        "documentation": {}
    },
    {
        "label": "parse_working_storage",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def parse_working_storage(ctx, static_analysis):\n    \"\"\"\n      WORKING-STORAGE SECTION     .\n     `REDEFINES`, `OCCURS`,  `88 LEVEL` conditions.\n    :param ctx:  parse tree context  WORKING-STORAGE SECTION.\n    :return:      .\n    \"\"\"\n    # workingStorageTree = find_working_storage_section(ctx)\n    variables = []\n    parent_entry = None  #    parent   88 LEVEL conditions",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "visit_data_description_entry",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def visit_data_description_entry(ctx):\n    \"\"\"\n         ().\n    :param ctx:  parse tree context  DataDescriptionEntry.\n    :return:  dictionary     .\n    \"\"\"\n    var_entry = {\n        \"Level\": None,\n        \"Name\": None,\n        \"PIC\": None,",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "get_value",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def get_value(ctx) -> str:\n    \"\"\"   `PIC` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()\n    else:\n        return \"\"\ndef visit_picture_clause(ctx) -> str:\n    \"\"\"   `PIC` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "visit_picture_clause",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def visit_picture_clause(ctx) -> str:\n    \"\"\"   `PIC` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()\n    else:\n        return \"\"\ndef visit_value_clause(ctx) -> str:\n    \"\"\"   `VALUE` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "visit_value_clause",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def visit_value_clause(ctx) -> str:\n    \"\"\"   `VALUE` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()\n    else:\n        return \"\"\ndef visit_occurs_clause(ctx) -> str:\n    \"\"\"   `OCCURS` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "visit_occurs_clause",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def visit_occurs_clause(ctx) -> str:\n    \"\"\"   `OCCURS` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()\n    else:\n        return \"\"\ndef visit_redefines_clause(ctx) -> str:\n    \"\"\"   `REDEFINES` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "visit_redefines_clause",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def visit_redefines_clause(ctx) -> str:\n    \"\"\"   `REDEFINES` . \"\"\"\n    if ctx.getChildCount() > 1:\n        return ctx.getChild(1).getText().strip()\n    else:\n        return \"\"\ndef visit_condition_clause(ctx):\n    \"\"\" \n      88 LEVEL condition names    .\n    :param ctx:  parse tree context  88 LEVEL condition.",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "visit_condition_clause",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def visit_condition_clause(ctx):\n    \"\"\" \n      88 LEVEL condition names    .\n    :param ctx:  parse tree context  88 LEVEL condition.\n    :return:  dictionary   condition   VALUE .\n    \"\"\"\n    condition = {\"Level\": \"88\", \"Name\": None, \"VALUE\": None}\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ConditionNameContext):\n            condition[\"Name\"] = child.getText()",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "get_variables_json",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def get_variables_json(variables) -> str:\n    \"\"\"      JSON. \"\"\"\n    return json.dumps(variables, indent=4)\ndef get_variables_raw(variables) -> str:\n    \"\"\"      JSON. \"\"\"\n    return variables    \ndef variables_to_json(variables) -> str:\n    \"\"\"      JSON. \"\"\"\n    return convert_cobol_to_json(variables)\ndef cobol_pic_to_json_type(pic):",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "get_variables_raw",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def get_variables_raw(variables) -> str:\n    \"\"\"      JSON. \"\"\"\n    return variables    \ndef variables_to_json(variables) -> str:\n    \"\"\"      JSON. \"\"\"\n    return convert_cobol_to_json(variables)\ndef cobol_pic_to_json_type(pic):\n    \"\"\"\n      COBOL PIC format  JSON-compatible type.\n    \"\"\"",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "variables_to_json",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def variables_to_json(variables) -> str:\n    \"\"\"      JSON. \"\"\"\n    return convert_cobol_to_json(variables)\ndef cobol_pic_to_json_type(pic):\n    \"\"\"\n      COBOL PIC format  JSON-compatible type.\n    \"\"\"\n    if pic is None:\n        return \"object\"  #    PIC,   struct container\n    #  string (PIC X(n))",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "cobol_pic_to_json_type",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def cobol_pic_to_json_type(pic):\n    \"\"\"\n      COBOL PIC format  JSON-compatible type.\n    \"\"\"\n    if pic is None:\n        return \"object\"  #    PIC,   struct container\n    #  string (PIC X(n))\n    match = re.match(r'X\\((\\d+)\\)', pic)\n    if match:\n        return {\"type\": \"string\", \"length\": int(match.group(1))}",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "convert_cobol_to_json",
        "kind": 2,
        "importPath": "parse_working_storage_section",
        "description": "parse_working_storage_section",
        "peekOfCode": "def convert_cobol_to_json(variables):\n    \"\"\"\n     COBOL variables   JSON  nested records.\n    \"\"\"\n    json_structure = []\n    record_stack = []  # Stack  nested structures\n    for var in variables:\n        json_entry = {\n            \"name\": var[\"Name\"] if var[\"Name\"] != \"FILLER\" else f\"unused_{id(var)}\",\n            \"level\": int(var[\"Level\"]),",
        "detail": "parse_working_storage_section",
        "documentation": {}
    },
    {
        "label": "cobol_pic_to_c_type",
        "kind": 2,
        "importPath": "convert_to_c_structs",
        "description": "convert_to_c_structs",
        "peekOfCode": "def cobol_pic_to_c_type(pic):\n    \"\"\"\n      COBOL PIC format  C  .\n    \"\"\"\n    if pic is None:\n        return \"void\"  #    PIC,   struct container\n    #  string (PIC X(n))\n    match = re.match(r'X\\((\\d+)\\)', pic)\n    if match:\n        length = int(match.group(1))",
        "detail": "convert_to_c_structs",
        "documentation": {}
    },
    {
        "label": "convert_cobol_to_c",
        "kind": 2,
        "importPath": "convert_to_c_structs",
        "description": "convert_to_c_structs",
        "peekOfCode": "def convert_cobol_to_c(variables):\n    \"\"\"\n      COBOL variables  C struct.\n    \"\"\"\n    struct_lines = [\"typedef struct {\"]\n    for var in variables:\n        c_type = cobol_pic_to_c_type(var[\"PIC\"])\n        var_name = var[\"Name\"] if var[\"Name\"] != \"FILLER\" else f\"unused_{id(var)}\"\n        #   OCCURS,   array\n        if var[\"OCCURS\"]:",
        "detail": "convert_to_c_structs",
        "documentation": {}
    },
    {
        "label": "cobol_pic_to_json_type",
        "kind": 2,
        "importPath": "convert_to_c_structs",
        "description": "convert_to_c_structs",
        "peekOfCode": "def cobol_pic_to_json_type(pic):\n    \"\"\"\n      COBOL PIC format  JSON-compatible type.\n    \"\"\"\n    if pic is None:\n        return \"object\"  #    PIC,   struct container\n    #  string (PIC X(n))\n    match = re.match(r'X\\((\\d+)\\)', pic)\n    if match:\n        return {\"type\": \"string\", \"length\": int(match.group(1))}",
        "detail": "convert_to_c_structs",
        "documentation": {}
    },
    {
        "label": "convert_cobol_to_json",
        "kind": 2,
        "importPath": "convert_to_c_structs",
        "description": "convert_to_c_structs",
        "peekOfCode": "def convert_cobol_to_json(variables):\n    \"\"\"\n     COBOL variables   JSON  nested records.\n    \"\"\"\n    json_structure = []\n    record_stack = []  # Stack  nested structures\n    for var in variables:\n        json_entry = {\n            \"name\": var[\"Name\"] if var[\"Name\"] != \"FILLER\" else f\"unused_{id(var)}\",\n            \"level\": int(var[\"Level\"]),",
        "detail": "convert_to_c_structs",
        "documentation": {}
    },
    {
        "label": "variables",
        "kind": 5,
        "importPath": "convert_to_c_structs",
        "description": "convert_to_c_structs",
        "peekOfCode": "variables = [{'Level': '77', 'Name': 'RC', 'PIC': 'S9(4)', 'VALUE': '+0', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '77', 'Name': 'SYSOUT-TOKEN', 'PIC': 'X(8)', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'DOGEMSG', 'PIC': None, 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DOGEID', 'PIC': 'X(10)B', 'VALUE': \"'DOGECICS99'\", 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'ADDRSS', 'PIC': 'X(34)B', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'AMOUNT', 'PIC': 'Z(02),Z(03),Z(02)9.9(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'DOGEMSG-LEN', 'PIC': '99', 'VALUE': '61', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'TRANSACTION', 'PIC': None, 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'TDATE', 'PIC': 'X(10)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'NUM-DATE', 'PIC': '9(10)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': 'TDATE', 'CONDITIONS': []}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'TADDRSS', 'PIC': 'X(34)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'TLABEL', 'PIC': 'X(10)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'TAMOUNT', 'PIC': None, 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '10', 'Name': 'TAMT-SIGN', 'PIC': 'X', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': [{'Level': '88', 'Name': 'TAMT-SIGN-POSITIVE', 'VALUE': \"'+'\"}, {'Level': '88', 'Name': 'TAMT-SIGN-NEGATIVE', 'VALUE': \"'-'\"}]}, {'Level': '10', 'Name': 'TAMT-INTEGER-PART', 'PIC': 'X(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '10', 'Name': 'TAMT-DEC-POINT', 'PIC': 'X', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '10', 'Name': 'TAMT-DECIMAL-PART', 'PIC': 'X(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'THE-AMOUNT', 'PIC': 'S9(8)V9(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'FILLER', 'PIC': None, 'VALUE': None, 'OCCURS': None, 'REDEFINES': 'THE-AMOUNT', 'CONDITIONS': []}, {'Level': '05', 'Name': 'THE-AMOUNT-INTEGER', 'PIC': 'X(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'THE-AMOUNT-DECIMAL', 'PIC': 'S9(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'AVAILABLE-AMOUNT', 'PIC': 'S9(8)V9(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'RECENT-COLOR', 'PIC': 'X', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'DISPLAY-TRAN', 'PIC': None, 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DDATE', 'PIC': 'X(10)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DLABEL', 'PIC': 'X(10)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DSIGN', 'PIC': 'X', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DAMOUNT', 'PIC': 'Z(02),Z(03),Z(02)9.9(8)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DTYPE', 'PIC': 'XXXX', 'VALUE': \"'DOGE'\", 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'TEMP-DATE', 'PIC': '9(15)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'DOGEMSG-LEN', 'PIC': '99', 'VALUE': '61', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'START-RECORD-ID', 'PIC': '9(10)', 'VALUE': '9999999999', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'SINCE-EPOCH', 'PIC': 'S9(15)', 'VALUE': '+2208988800000', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'RESPONSE-CODE', 'PIC': 'S9(4)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'RESPONSE-CODE2', 'PIC': 'S9(4)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'DOGECOMMS-AREA', 'PIC': None, 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '05', 'Name': 'DOGE-FLAG', 'PIC': 'X', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': [{'Level': '88', 'Name': 'SUCH-DOGE', 'VALUE': \"'D'\"}, {'Level': '88', 'Name': 'WOW-MENU', 'VALUE': \"'W'\"}, {'Level': '88', 'Name': 'SUCH-SEND', 'VALUE': \"'S'\"}, {'Level': '88', 'Name': 'SUCH-HISTORY', 'VALUE': \"'T'\"}]}, {'Level': '05', 'Name': 'FILLER', 'PIC': 'X(9)', 'VALUE': None, 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}, {'Level': '01', 'Name': 'WTO-MESSAGE', 'PIC': 'X(38)', 'VALUE': 'SPACES', 'OCCURS': None, 'REDEFINES': None, 'CONDITIONS': []}]\ndef cobol_pic_to_json_type(pic):\n    \"\"\"\n      COBOL PIC format  JSON-compatible type.\n    \"\"\"\n    if pic is None:\n        return \"object\"  #    PIC,   struct container\n    #  string (PIC X(n))\n    match = re.match(r'X\\((\\d+)\\)', pic)\n    if match:",
        "detail": "convert_to_c_structs",
        "documentation": {}
    },
    {
        "label": "parse_linkage_section",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def parse_linkage_section(ctx, static_analysis):\n    \"\"\"\n      LINKAGE SECTION     .\n     `REDEFINES`, `OCCURS`, `88 LEVEL` conditions.\n    :param ctx:  parse tree context  LINKAGE SECTION.\n    :return:      .\n    \"\"\"\n    variables = []\n    parent_entry = None\n    for child in context_info.get_children(ctx):",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "visit_data_description_entry",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def visit_data_description_entry(ctx):\n    \"\"\"\n        LINKAGE SECTION.\n    :param ctx:  parse tree context  DataDescriptionEntry.\n    :return: Dictionary     .\n    \"\"\"\n    var_entry = {\n        \"Level\": None,\n        \"Name\": None,\n        \"PIC\": None,",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "visit_picture_clause",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def visit_picture_clause(ctx):\n    return ctx.getText().replace(\"PIC\", \"\").strip()\ndef visit_value_clause(ctx):\n    return ctx.getText().replace(\"VALUE\", \"\").strip()\ndef visit_occurs_clause(ctx):\n    return ctx.getText().replace(\"OCCURS\", \"\").strip()\ndef visit_redefines_clause(ctx):\n    return ctx.getText().replace(\"REDEFINES\", \"\").strip()\ndef visit_condition_clause(ctx):\n    \"\"\" ",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "visit_value_clause",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def visit_value_clause(ctx):\n    return ctx.getText().replace(\"VALUE\", \"\").strip()\ndef visit_occurs_clause(ctx):\n    return ctx.getText().replace(\"OCCURS\", \"\").strip()\ndef visit_redefines_clause(ctx):\n    return ctx.getText().replace(\"REDEFINES\", \"\").strip()\ndef visit_condition_clause(ctx):\n    \"\"\" \n      88 LEVEL condition names    .\n    :param ctx:  parse tree context  88 LEVEL condition.",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "visit_occurs_clause",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def visit_occurs_clause(ctx):\n    return ctx.getText().replace(\"OCCURS\", \"\").strip()\ndef visit_redefines_clause(ctx):\n    return ctx.getText().replace(\"REDEFINES\", \"\").strip()\ndef visit_condition_clause(ctx):\n    \"\"\" \n      88 LEVEL condition names    .\n    :param ctx:  parse tree context  88 LEVEL condition.\n    :return: Dictionary   condition   VALUE .\n    \"\"\"",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "visit_redefines_clause",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def visit_redefines_clause(ctx):\n    return ctx.getText().replace(\"REDEFINES\", \"\").strip()\ndef visit_condition_clause(ctx):\n    \"\"\" \n      88 LEVEL condition names    .\n    :param ctx:  parse tree context  88 LEVEL condition.\n    :return: Dictionary   condition   VALUE .\n    \"\"\"\n    condition = {\"Level\": \"88\", \"Name\": None, \"VALUE\": None}\n    for child in context_info.get_children(ctx):",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "visit_condition_clause",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def visit_condition_clause(ctx):\n    \"\"\" \n      88 LEVEL condition names    .\n    :param ctx:  parse tree context  88 LEVEL condition.\n    :return: Dictionary   condition   VALUE .\n    \"\"\"\n    condition = {\"Level\": \"88\", \"Name\": None, \"VALUE\": None}\n    for child in context_info.get_children(ctx):\n        if isinstance(child, Cobol85Parser.ConditionNameContext):\n            condition[\"Name\"] = child.getText()",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "get_linkage_json",
        "kind": 2,
        "importPath": "parse_linkage_section",
        "description": "parse_linkage_section",
        "peekOfCode": "def get_linkage_json(variables):\n    \"\"\"     LINKAGE SECTION  JSON. \"\"\"\n    return json.dumps(variables, indent=4)",
        "detail": "parse_linkage_section",
        "documentation": {}
    },
    {
        "label": "CustomErrorListener",
        "kind": 6,
        "importPath": "custom_error_listener",
        "description": "custom_error_listener",
        "peekOfCode": "class CustomErrorListener(ErrorListener):\n    def __init__(self):\n        super(CustomErrorListener, self).__init__()\n        self.errors = []\n    def syntaxError(self, recognizer, offendingSymbol, line, column, msg, e):\n        self.errors.append(f\"Line {line}:{column} - {msg}\")\n    def get_errors(self):\n        return self.errors",
        "detail": "custom_error_listener",
        "documentation": {}
    }
]